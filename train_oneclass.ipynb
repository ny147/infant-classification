{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import shutil\n",
    "#import ftransc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 files belonging to 2 classes.\n",
      "Found 137 files belonging to 2 classes.\n",
      "['hungry', 'non_hungry']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_directory = './data/mel_freq/train_oneclass/hungry_one'\n",
    "test_directory = './data/mel_freq/test_oneclass/hungry_one'\n",
    "#train_directory = './img_data/mel_spectrogram/train'\n",
    "#test_directory = './img_data/mel_spectrogram/test'\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_directory, labels='inferred', label_mode='int', image_size=(256, 256), seed=321,\n",
    "    validation_split=None, subset=None)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_directory, labels='inferred', label_mode='int', image_size=(256, 256),\n",
    "    validation_split=None, subset=None)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "for images, labels in train_ds.unbatch().take(-1):\n",
    "    x_train.append(images.numpy())\n",
    "    y_train.append(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[]\n",
    "y_test=[]\n",
    "for images, labels in test_ds.unbatch().take(-1):\n",
    "    x_test.append(images.numpy())\n",
    "    y_test.append(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "def create_weight(n_sample,n_class,n_class_sample):\n",
    "    weight = n_sample/(n_class*n_class_sample)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0:0, 1:0}\n",
    "class_count = np.array([254,49])\n",
    "for i in range(num_classes):\n",
    "    class_weights[i]=create_weight(303,num_classes,class_count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " tf.cast (TFOpLambda)        (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 8, 8, 2048)        23564800  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,696,001\n",
      "Trainable params: 131,201\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.ResNet50V2(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    ") \n",
    "\n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "scale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
    "x = scale_layer(inputs)\n",
    "\n",
    "x = tf.cast(x,tf.float32)\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" #model = tf.keras.Sequential([\\n            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\\n            tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\\n            tf.keras.layers.MaxPooling2D((2,2)),\\n            tf.keras.layers.Dropout(0.2),\\n            tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \\n            tf.keras.layers.MaxPooling2D((2,2)),\\n            tf.keras.layers.Dropout(0.2),\\n            tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\\n            tf.keras.layers.MaxPooling2D((2,2)),\\n            tf.keras.layers.Flatten(),\\n            tf.keras.layers.Dense(64, activation='relu'),\\n            tf.keras.layers.Dense(1, activation='sigmoid')\\n        ])\\nmodel.summary() \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' #model = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "            tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2,2)),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \n",
    "            tf.keras.layers.MaxPooling2D((2,2)),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2,2)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "model.summary() '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet \n",
    "#inception v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()# modify weight in Adam\n",
    "metrics = ['accuracy']\n",
    "model.compile (optimizer = optimizer,loss =  loss_fn,metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 32s 5s/step - loss: 0.5672 - accuracy: 0.7421 - val_loss: 0.2609 - val_accuracy: 0.9390\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.4624 - accuracy: 0.9263 - val_loss: 0.4026 - val_accuracy: 0.9390\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 19s 3s/step - loss: 0.4110 - accuracy: 0.9263 - val_loss: 0.3735 - val_accuracy: 0.9390\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 16s 3s/step - loss: 0.4041 - accuracy: 0.9316 - val_loss: 0.3076 - val_accuracy: 0.9390\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 22s 4s/step - loss: 0.3834 - accuracy: 0.9263 - val_loss: 0.3226 - val_accuracy: 0.9390\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.3909 - accuracy: 0.9368 - val_loss: 0.3014 - val_accuracy: 0.9390\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.3556 - accuracy: 0.9421 - val_loss: 0.3067 - val_accuracy: 0.9390\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.3621 - accuracy: 0.9368 - val_loss: 0.2566 - val_accuracy: 0.9390\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.3487 - accuracy: 0.9368 - val_loss: 0.3436 - val_accuracy: 0.9512\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.3191 - accuracy: 0.9421 - val_loss: 0.2826 - val_accuracy: 0.9390\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.3053 - accuracy: 0.9474 - val_loss: 0.2600 - val_accuracy: 0.9390\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.3162 - accuracy: 0.9316 - val_loss: 0.2879 - val_accuracy: 0.9390\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.2807 - accuracy: 0.9474 - val_loss: 0.2452 - val_accuracy: 0.9390\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.2450 - accuracy: 0.9526 - val_loss: 0.2649 - val_accuracy: 0.9390\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.2459 - accuracy: 0.9684 - val_loss: 0.2706 - val_accuracy: 0.9268\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.2286 - accuracy: 0.9579 - val_loss: 0.2428 - val_accuracy: 0.9390\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.2067 - accuracy: 0.9842 - val_loss: 0.2367 - val_accuracy: 0.9390\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 27s 5s/step - loss: 0.2117 - accuracy: 0.9737 - val_loss: 0.2569 - val_accuracy: 0.9390\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.1973 - accuracy: 0.9789 - val_loss: 0.2500 - val_accuracy: 0.9512\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 27s 5s/step - loss: 0.1707 - accuracy: 0.9947 - val_loss: 0.2124 - val_accuracy: 0.9390\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.1738 - accuracy: 0.9842 - val_loss: 0.2277 - val_accuracy: 0.9390\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.1707 - accuracy: 0.9842 - val_loss: 0.2332 - val_accuracy: 0.9390\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 27s 5s/step - loss: 0.1606 - accuracy: 0.9947 - val_loss: 0.2145 - val_accuracy: 0.9390\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 27s 5s/step - loss: 0.1579 - accuracy: 0.9895 - val_loss: 0.2279 - val_accuracy: 0.9390\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.1393 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9512\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.1332 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9390\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.1265 - accuracy: 0.9842 - val_loss: 0.2017 - val_accuracy: 0.9268\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.1116 - accuracy: 0.9947 - val_loss: 0.1999 - val_accuracy: 0.9268\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.1239 - accuracy: 0.9895 - val_loss: 0.2128 - val_accuracy: 0.9390\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 26s 5s/step - loss: 0.0951 - accuracy: 0.9895 - val_loss: 0.1985 - val_accuracy: 0.9390\n"
     ]
    }
   ],
   "source": [
    "# Set the epocks\n",
    "# ทำ stop + validation\n",
    "epochs = 30\n",
    "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights,callbacks=callback)\n",
    "\n",
    "#history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " tf.cast (TFOpLambda)        (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 8, 8, 2048)        23564800  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,696,001\n",
      "Trainable params: 23,650,561\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "6/6 [==============================] - 96s 16s/step - loss: 1.1394 - binary_accuracy: 0.6474 - val_loss: 0.2282 - val_binary_accuracy: 0.9390\n",
      "Epoch 2/15\n",
      "6/6 [==============================] - 90s 15s/step - loss: 0.5675 - binary_accuracy: 0.8421 - val_loss: 0.4499 - val_binary_accuracy: 0.9024\n",
      "Epoch 3/15\n",
      "6/6 [==============================] - 88s 15s/step - loss: 0.4725 - binary_accuracy: 0.9158 - val_loss: 0.4563 - val_binary_accuracy: 0.9390\n",
      "Epoch 4/15\n",
      "6/6 [==============================] - 86s 14s/step - loss: 0.4343 - binary_accuracy: 0.8842 - val_loss: 0.3097 - val_binary_accuracy: 0.9390\n",
      "Epoch 5/15\n",
      "6/6 [==============================] - 89s 15s/step - loss: 0.4329 - binary_accuracy: 0.9316 - val_loss: 0.3534 - val_binary_accuracy: 0.9390\n",
      "Epoch 6/15\n",
      "6/6 [==============================] - 88s 15s/step - loss: 0.4091 - binary_accuracy: 0.9000 - val_loss: 0.2887 - val_binary_accuracy: 0.9390\n",
      "Epoch 7/15\n",
      "6/6 [==============================] - 89s 15s/step - loss: 0.4624 - binary_accuracy: 0.9316 - val_loss: 0.4235 - val_binary_accuracy: 0.9268\n",
      "Epoch 8/15\n",
      "6/6 [==============================] - 65s 10s/step - loss: 0.3695 - binary_accuracy: 0.9211 - val_loss: 0.3130 - val_binary_accuracy: 0.9146\n",
      "Epoch 9/15\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.3655 - binary_accuracy: 0.8789 - val_loss: 0.5337 - val_binary_accuracy: 0.6951\n",
      "Epoch 10/15\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3396 - binary_accuracy: 0.8737 - val_loss: 0.2363 - val_binary_accuracy: 0.9268\n",
      "Epoch 11/15\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3002 - binary_accuracy: 0.8474 - val_loss: 0.2239 - val_binary_accuracy: 0.9390\n",
      "Epoch 12/15\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2597 - binary_accuracy: 0.9368 - val_loss: 0.3963 - val_binary_accuracy: 0.8171\n",
      "Epoch 13/15\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2191 - binary_accuracy: 0.9474 - val_loss: 0.1877 - val_binary_accuracy: 0.9390\n",
      "Epoch 14/15\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1300 - binary_accuracy: 0.9526 - val_loss: 0.2694 - val_binary_accuracy: 0.9390\n",
      "Epoch 15/15\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1012 - binary_accuracy: 0.9737 - val_loss: 0.2584 - val_binary_accuracy: 0.8415\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(5e-5),  # Low learning rate\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 15\n",
    "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_transform(pred):\n",
    "    if pred > 0.5:\n",
    "        predicted = 1\n",
    "    else:\n",
    "        predicted = 0\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "\n",
    "vfunc = np.vectorize(binary_transform)\n",
    "y_pred = vfunc(pred)\n",
    "actual = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEHCAYAAABlbhceAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAcDklEQVR4nO3de7xd87nv8c93rYjQiCBkIyGaRusepHELTbEpdVqKg6MamrKrPd3KbrfY1WrPPlW3sretOEGbuNY1ZdutIHVtkZOkbnFJiEQQISIRcUmy1rP/GGMxLesy1lxzrrHGnN/36zVea8wxf3OMZ67wjN96xm/8hiICMzMrhoa8AzAzs+yctM3MCsRJ28ysQJy0zcwKxEnbzKxA+uQdQC0btGFjDBu6Vt5hWBfMeWHDvEOwLlrx3qIlEbFxd/Zx4Jc/E28tbcrUduaTH06NiK9053jd4aRdRcOGrsX0qUPzDsO64CtfPTbvEKyL7pn1iwXd3cdbS5uYPnWLTG0bN507qLvH6w4nbTOrewE005x3GJk4aZtZ3QuC1ZGtPJI3J20zM9zTNjMrjCBoKsiUHk7aZmZAM07aZmaFEECTk7aZWXG4p21mVhABrHZN28ysGIJwecTMrDACmoqRs520zcySOyKLwUnbzAzRhPIOIhMnbTOrewE0uzxiZlYMAawqyOMFnLTNzIDmcHnEzKwQkjsinbTNzAohEE0FKY8UI0ozsyprDmVaOiPpt5LekPR0ybYNJd0jaW76c4N0uyRdLOkFSU9K2qWz/Ttpm1ndC8SqaMy0ZDAJaP0MyQnAtIgYAUxLXwMcBIxIl5OAyzrbuZO2mdW95OaahkxLp/uKeBBY2mrz14HJ6fpk4NCS7VdH4lFgoKRNO9q/a9pmZnTpQuQgSTNKXk+MiImdfGZwRCwCiIhFkjZJt28OLCxp90q6bVF7O3LSNrO6FyGaInPhYUlEjKrQods6U3R4m4/LI2ZmQDPKtJRpcUvZI/35Rrr9FWBoSbshwGsd7chJ28zqXjJOuyHTUqY7gHHp+jjg9pLt30pHkewOLG8po7TH5REzq3uBWB2VSYeSbgDGktS+XwHOAs4BbpI0HngZODJt/kfgYOAF4D3ghM7276RtZgY0Veg29og4pp239mujbQDf78r+nbTNrO4V6Y5IJ20zM6A5++iRXDlpm1nda7kQWQRO2mZW9wJVrKZdbU7aZlb3IqjY6JFqK0aUZmZV1a0bZ3qUk7aZ1b2ArtzGnisnbTMzfCHSzKwwgmwPOOgNnLTNrO4FvhBpZlYg8oN9zcyKIvAdkWZmheKetplZQUTIPW0zsyLxOG0zs4JIHoLQmHcYmThpm1ndSy5EuqZtZlYYviPSzKwgfEekmVnBNLunbWZWDBGVe7BvtTlpm1ndC8SaZo8eMTMrDN8RaYX161OH8ti9Axg4aA0T73segAf/c32u+fXfsXBuPy7+4xy23ul9AN5Z2si/njSMOY+vy9//z6X877NfzTN0A0495VF2G/0qy5b147vf/yoAZ5z+MEOGvANA/8+s5t2Va/H9HxycZ5i9iof89QBJw4A7I2L7nEOpOQcctZSvnbCE80/Z4qNtw77wAT+7cj4Xnz70E2379gvG/fh15j/fj/nP9evpUK0N99z7Wf7zzq350WmPfLTtV+eO+Wj9xPGzWPneWnmE1osV5zb2YkTZC0gq7Amuq3bYfSXrbdD0iW1bjPiQoZ/78FNt+63bzPa7raTv2tFT4Vknnp69CStW9G3n3WCfvV/m/ge27NGYiqA5fU5kZ0veip60GyVdIWm2pLslrSPpfkmjACQNkjQ/XT9e0m2S7pI0V9J5LTuRNF7SnPSzV0i6JN0+SdKFku4Dzk8/t3H6XoOkFyQN6vmvbVae7bd7k7eX9eO11wbkHUqvEgGrmxszLXkreu9xBHBMRJwo6Sbg8E7ajwR2Bj4Enpf0H0AT8FNgF2AF8GfgiZLPbA3sHxFNkpYBxwL/BuwPPBERS0oPIOkk4CSALTYv+q/Xas3YL813L7sNRbq5pug97Zci4vF0fSYwrJP20yJieUR8ADwDbAmMBh6IiKURsRq4udVnbo6IllrBb4FvpevfBn7X+gARMTEiRkXEqI03yv+sbNaioaGZvfZ8hQcfdNJuS1HKI0XvCpYWWZuAdYA1fHwyan1lrHX7PtDpv8LKlpWIWChpsaR9gd1Iet1mhbDzzq+z8JUBLHlr3bxD6XU8eiRf84FdgenAERnaTwcukrQBSXnkcOCpDtpfCVwLXFPSA68pvzp5S558pD/Ll/bh2F235bh/ep31Nmji0jM3Z/lbffjpcZ9l+Hbvc/YN8wD41uhtWfluA2tWiUemrs/ZN7zIllt/+qKl9YwJ//wXdtxhMQMGfMg1k6dw7XU7MvXu4YzdZ4FLIx2o1OgRSacC3yE5FzwFnABsCvwe2BCYBRwXEavK2X8tJu0LgJskHUdSn+5QRLwq6WzgMeA1krLJ8g4+cgdJWeRTpZFaccZlC9rcvtdBbf9arp7+TDXDsS4657y92tz+64v26OFICiQqU9OWtDnwj8C2EfF+eq3taOBg4KKI+L2ky4HxwGXlHKOwSTsi5gPbl7y+oOTtHUvWz0zfnwRMKml/SEmb6yNiYjqsbwpwd9rm+DYOvRPJBcjnuvUFzKzXCGBN5cZp9wHWkbQaWBdYBOwL/K/0/cnAzykzaRf9QmSl/FzS48DTwEvAH9pqJGkCcCtwRg/GZmZV1lLTzrJ0uJ+IV0n+2n+ZJFkvJxkksSwi1qTNXgE2LzfWwva0KykifpSx3TnAOVUOx8xy0IXyyCBJM0peT4yIiQDptbGvA1sBy0hGox3Uxj7KvhvNSdvM6l4Xx2kviYhR7by3P8lQ5DcBJN0G7AkMlNQn7W0PIbl+VhaXR8zMqNg47ZeB3SWtK0nAfiSDG+7j49Fs44Dby43TSdvMLCpW034MuIVkWN9TJDl2InA6cJqkF4CNgKvKDdXlETOrewGsaa5MHzYizgLOarV5Hsnd193mpG1mda9Ic484aZuZAeGkbWZWHL1hMqgsnLTNrO5FeMIoM7MCEU0VuhBZbU7aZma4pm1mVhieT9vMrEgiqWsXgZO2mRkePWJmVhiBa9pmZgUimpqdtM3MCsM9bTOzgohw0jYzKxQP+TMzKxAP+TMzK4hANPs2djOz4ihIR9tJ28wMX4g0MyuYgnS1203akgZ09MGIeKfy4ZiZ5aMWetqzSc49pd+k5XUAW1QxLjOzHlX40SMRMbQnAzEzy0sEREFGj2SKUtLRkv4lXR8iadfqhmVm1rMisi156zRpS7oE+DJwXLrpPeDyagZlZtbjIuOSsyyjR/aMiF0k/Q0gIpZK6lvluMzMepBq4kJki9WSGkjPMZI2ApqrGpWZWU/rBb3oLLLUtH8D3ApsLOkXwMPAuVWNysysJ6U312RZ8tZpTzsirpY0E9g/3XRkRDxd3bDMzHpYL0jIWWS9I7IRWE3yB0QxxsWYmXVFrZRHJP0EuAHYDBgCXC/pjGoHZmbWo2po9Mg3gV0j4j0ASb8EZgK/qmZgZmY9JihMeSRLqWMBn0zufYB51QnHzCwflbq5RtJASbdIek7Ss5L2kLShpHskzU1/blBunO0mbUkXSbqQ5Gaa2ZKulHQF8BSwrNwDmpn1Ss3KtnTu34G7IuILwE7As8AEYFpEjACmpa/L0lF5pGWEyGzgv0q2P1ruwczMeitVoF6dzo66D3A8QESsAlZJ+jowNm02GbgfOL2cY3Q0YdRV5ezQzKxwunaRcZCkGSWvJ0bExHT9s8CbwO8k7URy/e8UYHBELAKIiEWSNik31E4vREoaDvwS2Bbo17I9IrYu96BmZr2LunIhcklEjGrnvT7ALsAPIuIxSf9ON0ohbclyIXIS8DuSebQPAm4Cfl/JIMzMcleZIX+vAK9ExGPp61tIkvhiSZsCpD/fKDfMLEl73YiYChARL0bEmSSz/pmZ1Y4KJO2IeB1YKOnz6ab9gGeAO4Bx6bZxwO3lhpllnPaHkgS8KOm7wKtA2fUYM7NeJ8g6MiSLHwDXpbOhzgNOIOkg3yRpPPAycGS5O8+StE8F+gP/SFLbXh/4drkHNDPrjSoxegQgIh4H2qp571eJ/WeZMKqlNrOCjx+EYGZWW3rBLepZdPQ09il08DUi4htVicjMzNrVUU/7kh6LokbNfWYAB+98QN5hWBfE4tl5h2A5qVR5pNo6urlmWk8GYmaWq4JMGJV1Pm0zs9oVFOYhik7aZmYUpzyS+Sk0ktauZiBmZrkqyEMQsjy5ZrSkp4C56eudJP1H1SMzM+tJtZK0gYuBQ4C3ACLiCXwbu5nVEEX2JW9ZatoNEbEguZP9I01VisfMLB+Vu429qrIk7YWSRgMhqZHkvvo51Q3LzKxn9YZedBZZkvbJJCWSLYDFwL3pNjOz2lErSTsi3gCO7oFYzMzy0Uvq1VlkeXLNFbRxDoqIk6oSkZlZHmolaZOUQ1r0Aw4DFlYnHDOznNRK0o6IG0tfS7oGuKdqEZmZ5aBmyiNt2ArYstKBmJnlqlaStqS3+fjrNABLqfDThc3MclUrFyLTZ0PuRPJcSIDmiCjIVzMz64KCZLYOb2NPE/SUiGhKl4J8LTOzLqqhuUemS9ql6pGYmeVE1MDcI5L6RMQaYAxwoqQXgZUk3y8iwonczGpDgGrgIQjTgV2AQ3soFjOz/PSCXnQWHSVtAUTEiz0Ui5lZfmogaW8s6bT23oyIC6sQj5lZLnpDvTqLjpJ2I9CftMdtZlbTaiBpL4qI/9NjkZiZ5aVGLkS6h21m9aMGetr79VgUZmY5K3xNOyKW9mQgZma5KnrSNjOrG73kFvUsstzGbmZW09SFJdP+pEZJf5N0Z/p6K0mPSZor6UZJfcuN1UnbzIxk9EiWJaNTgGdLXp8LXBQRI4C3gfHlxumkbWYGFZvlT9IQ4KvAlelrAfsCt6RNJtON6UFc0zYzg67UtAdJmlHyemJETCx5/W/APwPrpa83ApalE/ABvAJsXm6YTtpmZl2bdnVJRIxq6w1JhwBvRMRMSWNbNrd9xPI4aZuZQaVGj+wFfE3SwUA/YABJz3tgyXTXQ4DXyj2Aa9pmZlTmQmREnBERQyJiGHA08OeIOBa4DzgibTYOuL3cOJ20zcyo+pNrTgdOk/QCSY37qnJ35PKImVkVbq6JiPuB+9P1ecDoSuzXSdvMDApzR6STtpnVvZYH+xaBk7aZGbinbWZWGAFqLkbWdtI2M8PlETOzYnHSNjMrDve0zcyKxEnbzKwgune3Y49y0jazuie69ICDXDlpm5kBRDG62k7aZma4PGI16tBjF3DgYa8SAfNf6M9FZ23H6lWNeYdl7TjtwpfZbf8VLFvSh3/Y9/N5h9N7+WnsVos22vgDvnbMy5xy7G5878g9aWyALx24OO+wrAN337ghPzl2q7zDKIQKP9i3agqZtCUdL+mSvOOoR42NQd+1m2lobGbtfk289ebaeYdkHXj6sf6seNt/UGdRlKTtf82MJDVGRFPeceTprTf7cdvVw5j8p4dY9WEDsx7ZiL89ulHeYZl1X1CYC5FV62lLGibpWUlXSJot6W5J60gaKelRSU9KmiJpg7T9/ZLOlTRd0hxJe3dyiM0k3SVprqTzSo77bsn6EZImpeuTJF0s6a+S5kk6It3eIOnSNMY7Jf2x5L35kn4m6WFggqRZJfseIWlmxX5hBdB/vdXsPvYNTjhkDN88YB/6rdPElw9elHdYZhVR5SfXVEy1yyMjgN9ExHbAMuBw4Grg9IjYEXgKOKukfZ+IGA38sNX2towEjgJ2AI6SNDRDPJsCY4BDgHPSbd8AhqX7+Q6wR6vPfBARYyLil8BySSPT7ScAk1ofQNJJkmZImrGq+f0MIRXHyN2W8vpr6/DO231pWtPAX/68CdvstCzvsMwqIzIuOat20n4pIh5P12cCw4GBEfFAum0ysE9J+9tK2g7rZN/TImJ5RHwAPANsmSGeP0REc0Q8AwxOt40Bbk63v07yAM5SN5asXwmcIKmR5IRxfesDRMTEiBgVEaP6NqyTIaTiePP1fnxhh+Ws3a8JCEaOXsrClz6Td1hm3dbyEIQi9LSrXdP+sGS9CRiYsX0TncfWet8t7Ut/rf06+Ixa/WzPypL1W0n+AvgzMDMi3urkszXl+afX5+F7B3Px9Y/S1CTmPTeAP906JO+wrAMTLl3Ajnu8y/obruHaGc9wza8HM/UGX4f4lIjC1LR7+kLkcuBtSXtHxEPAccADnXymqxZL2gZ4HjgMWNFJ+4eBcZImAxsDY2mjBw0QER9ImgpcBoyvWMQFct3lw7nu8uF5h2EZnfO9LH+AGvSOkSFZ5DF6ZBxwuaR1gXkkteFKmgDcCSwEngb6d9L+VmC/tO0c4DGSk0t7riOpg9/d7UjNrNfoDaWPLKqWtCNiPrB9yesLSt7evY32Y0vWl9BBTTsiJlFyETAiDilZvwW4pY3PHN/qdf/0Z7OkH0XEu5I2AqaTXCAlItqKYQzw23of/mdWUwLw48YK5U5JA4G+wL+mFyQ/RdIUkoup+/ZkcGbWA4qRs3t30pZ0IHBuq80vRcRhlTxOaS+/k3YVPa6Z9R51Xx6phIiYCkzNOw4zqwMePWJmVhDh0SNmZoWR3FzjnraZWXG4p21mVhxF6WkXcj5tM7OKyjpZVCd5XdJQSfelM5zOlnRKun1DSfeks5Le0zK7aTmctM3MCNScbenEGuCfImIbkpsIvy9pW5I7tadFxAhgWvq6LE7aZmbw8aRRnS0d7iIWRcSsdH0F8CywOfB1kllNSX8eWm6YrmmbmXVtyN8gSTNKXk+MiImtG0kaBuxMMp/R4IhYBElil7RJuaE6aZuZQVdurlkSEaM6aiCpP8lkdD+MiHekzmaAzs7lETMzqNiTayStRZKwr4uIlge7LJa0afr+psAb5YbppG1mRjLkL8vS4T6SLvVVwLMRcWHJW3eQTEtN+vP2cuN0ecTMLICmiozT3ovk4S5PSWp51OK/kDyT9iZJ44GXgSPLPYCTtpnVPdF5LzqLiHiY9h9huF+3D4CTtplZoiB3RDppm5mBk7aZWWEEnjDKzKxIijJhlJO2mRkBzcXoajtpm5kFrmmbmRVKMTraTtpmZuCatplZsThpm5kVRAQ0FaM+4qRtZgbuaZuZFYqTtplZQQTQ+fMfewUnbTMzAsI1bTOz4nB5xMysIAKPHjEzKxT3tM3MiiKctM3MCiPwLH9mZoXinraZWYE4aZuZFUQE0dSUdxSZOGmbmYHviDQzKxSXR8zMCiL8jEgzs2JxT9vMrCh8IdLMrDg8NauZWcF4alYzs2IIINzTNjMriPBDEMzMCqUoPW1FQYa5FJGkN4EFecdRJYOAJXkHYV1Sq/9mW0bExt3ZgaS7SH4/WSyJiK9053jd4aRtZZE0IyJG5R2HZed/s9rQkHcAZmaWnZO2mVmBOGlbuSbmHYB1mf/NaoBr2mZmBeKetplZgThpm5kViJN2HZI0TNLTecdhZl3npG1VJ8l33vYgScdLuiTvOKw6nLTrV6OkKyTNlnS3pHUk3S9pFICkQZLmp+vHS7pN0l2S5ko6r2UnksZLmpN+9oqWZCFpkqQLJd0HnJ9+buP0vQZJL0jKegea9XKSGvOOoV44adevEcBvImI7YBlweCftRwJHATsAR0kaKmkz4KfA7sDfA19o9Zmtgf0j4lTgWuDYdPv+wBMRUYu3VGeSlqiebePEOVLSo5KelDRF0gZp+/slnStpenqS3LuTQ2zWzkn23ZL1IyRNStcnSbpY0l8lzZN0RLq9QdKlaYx3SvpjyXvzJf1M0sPABEmzSvY9QtLMiv3C7CNO2vXrpYh4PF2fCQzrpP20iFgeER8AzwBbAqOBByJiaUSsBm5u9ZmbI6LlcSC/Bb6Vrn8b+F13v0ANaOvEeTVwekTsCDwFnFXSvk9EjAZ+2Gp7Wz51ks0Qz6bAGOAQ4Jx02zdI/tvYAfgOsEerz3wQEWMi4pfAckkj0+0nAJMyHNO6yEm7fn1Yst5EMuPjGj7+b6Jfhvbq5BgrW1YiYiGwWNK+wG7An8qIuda0PnEOBwZGxAPptsnAPiXtbytpO6yTfbd1ku3MHyKiOSKeAQan28aQnHybI+J14L5Wn7mxZP1K4IS0VHIUcH2GY1oXOWlbqfnArun6ERnaTwe+JGmD9GJjZyWWK0nKJDeV9MDrWesT4cCM7VtOml3Zd0v70rvpOjoxq9XP9qwsWb8VOIikpz4zIt7q5LNWBidtK3UBcLKkv5JhmsqIeBU4G3gMuJekR7e8g4/cAfTHpZH2LAfeLqlXHwc80EH7ciyWtI2kBuCwDO0fBg5Pa9uDgbHtNUx79VOBy/C/cdV4KFYdioj5wPYlry8oeXvHkvUz0/cnUVKfjIhDStpcHxET0572FODutM3xbRx6J5ILkM916wvUtnHA5ZLWBeaR1IYraQJwJ7AQeJrkJNqRW4H90rZzSE7QHZ2YryOpg9/d7UitTZ57xLpF0gUko0H6kfyPekq08R+VpAnAycCxEfFwz0Zp3SGpf0S8K2kjkpLYXml9u622PwLWj4if9miQdcRJ28w6JOl+knp7X+C89C+vttpNIbmYum89D+esNidts4KSdCBwbqvNL0VEllq1FZSTtplZgXj0iJlZgThpm5kViJO25UpSk6THJT0t6eZ0qFu5+xor6c50/WvpiJX22g6U9L0yjvHzdIREpu2t2kxqmbcj47E8ha59ipO25e39iBgZEdsDq4Dvlr6pRJf/O42IOyLinA6aDAS6nLTN8uakbb3JQ8DnSmbAuxSYBQyVdICkRyTNSnvk/QEkfUXSc+lMc99o2VHpnNKSBqcz5j2RLnuSTIg0PO3ln5+2+7Gk/5/OsPeLkn39RNLzku4FPt/Zl5B0YrqfJyTd2uqvh/0lPZTO1HdI2r5R0vklx/6H7v4irXY5aVuvkN5ReRDJzHaQJMerI2JnkvktziSZ5nUXYAZwmqR+wBXA/wD2Bv6und1fTDIb4U7ALsBskjsDX0x7+T+WdADJrHujSWbI21XSPpJ2BY4GdiY5KXwxw9e5LSK+mB7vWWB8yXvDgC8BXyW587Ff+v7yiPhiuv8TJW2V4ThWh3wbu+VtHUktM909BFwFbAYsiIhH0+27A9sCf5EEyU0ej5DM3/1SRMwFkHQtcFIbx9iXdFrYdKKq5S3zVJc4IF3+lr7uT5LE1wOmRMR76THuyPCdtpf0f0lKMP1J5uNocVNENANzJc1Lv8MBwI4l9e7102PPyXAsqzNO2pa39yNiZOmGNDGXzh4n4J6IOKZVu5F8cta67hDwq4j4f62O8cMyjjEJODQinpB0PJ+cZKn1viI99g8iojS5I2lYF49rdcDlESuCR4G9JH0OQNK6krYGngO2kjQ8bXdMO5+fRjLvSUv9eACwgqQX3WIq8O2SWvnmkjYBHgQOU/JUmfVISjGdWQ9YJGktPn5aT4sj0xnzhgOfBZ5Pj31y2h5JW0v6TIbjWB1yT9t6vYh4M+2x3iBp7XTzmRExR9JJwH9JWkIyjej2beziFGCipPEkc0ufHBGPSPpLOqTuT2ldexvgkbSn/y7wzYiYJelG4HFgAUkJpzM/JZkNbwFJjb705PA8yXSrg4HvRsQHkq4kqXXPUnLwN4FDs/12rN74NnYzswJxecTMrECctM3MCsRJ28ysQJy0zcwKxEnbzKxAnLTNzArESdvMrED+GwURgERjBLcaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=class_names)\n",
    "disp.plot()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Hungry       0.93      0.87      0.90       128\n",
      "  Non_hungry       0.06      0.11      0.07         9\n",
      "\n",
      "    accuracy                           0.82       137\n",
      "   macro avg       0.49      0.49      0.49       137\n",
      "weighted avg       0.88      0.82      0.84       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred,target_names=[\"Hungry\",\"Non_hungry\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23bf0724a01b6ea9814e66f76182ea78c0ee849a72ca257c0e116bf83bb4960a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
