{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import shutil\n",
    "#import ftransc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49 files belonging to 4 classes.\n",
      "Found 26 files belonging to 4 classes.\n",
      "['belly_pain_data', 'burping_data', 'discomfort_data', 'tired_data']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_directory = './data/mel_freq/train_oneclass/no_hungry'\n",
    "test_directory = './data/mel_freq/test_oneclass/no_hungry'\n",
    "#train_directory = './img_data/mel_spectrogram/train'\n",
    "#test_directory = './img_data/mel_spectrogram/test'\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_directory, labels='inferred', label_mode='int', image_size=(256, 256), seed=321,\n",
    "    validation_split=None, subset=None)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_directory, labels='inferred', label_mode='int', image_size=(256, 256),\n",
    "    validation_split=None, subset=None)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(data):\n",
    "    new_data =[]\n",
    "    for i in data:\n",
    "        lab_data =[0,0,0,0]\n",
    "        lab_data[i] = 1\n",
    "        new_data.append(lab_data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "for images, labels in train_ds.unbatch().take(-1):\n",
    "    x_train.append(images.numpy())\n",
    "    y_train.append(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[]\n",
    "y_test=[]\n",
    "for images, labels in test_ds.unbatch().take(-1):\n",
    "    x_test.append(images.numpy())\n",
    "    y_test.append(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_train ==0)\n",
    "np.count_nonzero(y_train ==1)\n",
    "np.count_nonzero(y_train ==2)\n",
    "np.count_nonzero(y_train ==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = np.array([np.count_nonzero(y_train ==0),np.count_nonzero(y_train ==1),np.count_nonzero(y_train ==2),np.count_nonzero(y_train ==3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dummy(y_train)\n",
    "y_test = dummy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  5, 18, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 256\n",
    "img_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10+  5+ 18+ 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "\n",
    "def create_weight(n_sample,n_class,n_class_sample):\n",
    "    weight = n_sample/(n_class*n_class_sample)\n",
    "    return weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0:0, 1:0,2:0,3:0}\n",
    "\n",
    "for i in range(num_classes):\n",
    "    class_weights[i]=create_weight(49,num_classes,class_count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.225, 1: 2.45, 2: 0.6805555555555556, 3: 0.765625}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_5 (Rescaling)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " tf.cast_5 (TFOpLambda)      (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 8, 8, 2048)        23564800  \n",
      "                                                                 \n",
      " global_average_pooling2d_5   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 8196      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,572,996\n",
      "Trainable params: 8,196\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.ResNet50V2(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    ") \n",
    "\n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "scale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
    "x = scale_layer(inputs)\n",
    "\n",
    "x = tf.cast(x,tf.float32)\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "#x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = tf.keras.layers.Dense(4,activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" #model = tf.keras.Sequential([\\n            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\\n            tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\\n            tf.keras.layers.MaxPooling2D((2,2)),\\n            tf.keras.layers.Dropout(0.2),\\n            tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \\n            tf.keras.layers.MaxPooling2D((2,2)),\\n            tf.keras.layers.Dropout(0.2),\\n            tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\\n            tf.keras.layers.MaxPooling2D((2,2)),\\n            tf.keras.layers.Flatten(),\\n            tf.keras.layers.Dense(64, activation='relu'),\\n            tf.keras.layers.Dense(1, activation='sigmoid')\\n        ])\\nmodel.summary() \""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' #model = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "            tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2,2)),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \n",
    "            tf.keras.layers.MaxPooling2D((2,2)),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2,2)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "model.summary() '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet \n",
    "#inception v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()# modify weight in Adam\n",
    "metrics = ['accuracy']\n",
    "model.compile (optimizer = optimizer,loss =  loss_fn,metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 5s 1s/step - loss: 1.5956 - accuracy: 0.3265\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4692 - accuracy: 0.2449\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4140 - accuracy: 0.3061\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4210 - accuracy: 0.2857\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4127 - accuracy: 0.3673\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3593 - accuracy: 0.3061\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 3s 997ms/step - loss: 1.1946 - accuracy: 0.4694\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2129 - accuracy: 0.4286\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3043 - accuracy: 0.4082\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2117 - accuracy: 0.4694\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2002 - accuracy: 0.4490\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1642 - accuracy: 0.4898\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2095 - accuracy: 0.4082\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1872 - accuracy: 0.4082\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2196 - accuracy: 0.4490\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0761 - accuracy: 0.5918\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0956 - accuracy: 0.5918\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1015 - accuracy: 0.6122\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0677 - accuracy: 0.6327\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0729 - accuracy: 0.5510\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1067 - accuracy: 0.4490\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0505 - accuracy: 0.4694\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0362 - accuracy: 0.6327\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9782 - accuracy: 0.5918\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9807 - accuracy: 0.6122\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9940 - accuracy: 0.6122\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9733 - accuracy: 0.6939\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 3s 998ms/step - loss: 0.9495 - accuracy: 0.6531\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9293 - accuracy: 0.7347\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9712 - accuracy: 0.6327\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9241 - accuracy: 0.6122\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8945 - accuracy: 0.6735\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0330 - accuracy: 0.6122\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8444 - accuracy: 0.7347\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8581 - accuracy: 0.7143\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9254 - accuracy: 0.6531\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8932 - accuracy: 0.6531\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7604 - accuracy: 0.8163\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7822 - accuracy: 0.7551\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7911 - accuracy: 0.8571\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8406 - accuracy: 0.7755\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8145 - accuracy: 0.7755\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8055 - accuracy: 0.8163\n"
     ]
    }
   ],
   "source": [
    "# Set the epocks\n",
    "# ทำ stop + validation\n",
    "epochs = 50\n",
    "history = model.fit(x_train, y_train, epochs=epochs,callbacks=callback,class_weight = class_weights)\n",
    "\n",
    "#history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_5 (Rescaling)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " tf.cast_5 (TFOpLambda)      (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 8, 8, 2048)        23564800  \n",
      "                                                                 \n",
      " global_average_pooling2d_5   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 8196      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,572,996\n",
      "Trainable params: 23,527,556\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 17s 5s/step - loss: 0.7115 - binary_accuracy: 0.7806\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 14s 5s/step - loss: 0.8597 - binary_accuracy: 0.6276\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.6118 - binary_accuracy: 0.6939\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 14s 5s/step - loss: 0.5544 - binary_accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.5600 - binary_accuracy: 0.7449\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.5336 - binary_accuracy: 0.7602\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 14s 5s/step - loss: 0.5034 - binary_accuracy: 0.7551\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.4874 - binary_accuracy: 0.7704\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 14s 5s/step - loss: 0.4544 - binary_accuracy: 0.7959\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.4296 - binary_accuracy: 0.8061\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 14s 5s/step - loss: 0.4203 - binary_accuracy: 0.7908\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.3679 - binary_accuracy: 0.8469\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.3325 - binary_accuracy: 0.8980\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.2906 - binary_accuracy: 0.8980\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.2577 - binary_accuracy: 0.9082\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.2506 - binary_accuracy: 0.9388\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 14s 5s/step - loss: 0.1859 - binary_accuracy: 0.9388\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 14s 5s/step - loss: 0.1759 - binary_accuracy: 0.9286\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.1237 - binary_accuracy: 0.9796\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.1130 - binary_accuracy: 0.9541\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.1018 - binary_accuracy: 0.9643\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 14s 5s/step - loss: 0.0688 - binary_accuracy: 0.9847\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 14s 5s/step - loss: 0.0425 - binary_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 12s 4s/step - loss: 0.0325 - binary_accuracy: 0.9949\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 11s 4s/step - loss: 0.0167 - binary_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 10s 3s/step - loss: 0.0108 - binary_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 14s 5s/step - loss: 0.0082 - binary_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 14s 5s/step - loss: 0.0024 - binary_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 14s 5s/step - loss: 0.0036 - binary_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 14s 5s/step - loss: 0.0023 - binary_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 15s 5s/step - loss: 0.0020 - binary_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 5.5769e-04 - binary_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 10s 4s/step - loss: 4.4200e-04 - binary_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 4.4045e-04 - binary_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 1.6166e-04 - binary_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 3.1286e-04 - binary_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 7.1245e-05 - binary_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 9.6487e-05 - binary_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 5.5689e-05 - binary_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 3.6476e-05 - binary_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 9.3362e-05 - binary_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 9.1807e-05 - binary_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 5.1213e-05 - binary_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 3.9786e-05 - binary_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 13s 5s/step - loss: 5.7499e-05 - binary_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(5e-5),  # Low learning rate\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 50\n",
    "history = model.fit(x_train, y_train, epochs=epochs,callbacks=callback,class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "actual = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 3, 2, 0, 2, 2, 2, 2, 3, 3, 3, 0, 2, 2, 3, 1, 2, 2, 3, 2,\n",
       "       2, 3, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 2, 2, 0, 3, 0, 1, 2, 0, 0, 2, 3, 3, 3, 2, 1, 2, 2, 3, 2,\n",
       "       0, 3, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-498de5f81bc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \"\"\"\n\u001b[1;32m-> 1195\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.17      0.25         6\n",
      "           1       1.00      0.33      0.50         3\n",
      "           2       0.38      0.67      0.48         9\n",
      "           3       0.29      0.25      0.27         8\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.54      0.35      0.37        26\n",
      "weighted avg       0.45      0.38      0.36        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23bf0724a01b6ea9814e66f76182ea78c0ee849a72ca257c0e116bf83bb4960a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
