{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import shutil\n",
    "#import ftransc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 109 files belonging to 5 classes.\n",
      "Found 57 files belonging to 5 classes.\n",
      "['burping', 'discomfort', 'hungry', 'poop', 'tired']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_directory = './data/poly/mel_freq/train'\n",
    "test_directory = './data/poly/mel_freq/test'\n",
    "#train_directory = './img_data/mel_spectrogram/train'\n",
    "#test_directory = './img_data/mel_spectrogram/test'\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_directory, labels='inferred', label_mode='int', image_size=(256, 256), seed=321,\n",
    "    validation_split=None, subset=None)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_directory, labels='inferred', label_mode='int', image_size=(256, 256),\n",
    "    validation_split=None, subset=None)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(data):\n",
    "    new_data =[]\n",
    "    for i in data:\n",
    "        lab_data =[0,0,0,0,0]\n",
    "        lab_data[i] = 1\n",
    "        new_data.append(lab_data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "for images, labels in train_ds.unbatch().take(-1):\n",
    "    x_train.append(images.numpy())\n",
    "    y_train.append(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[]\n",
    "y_test=[]\n",
    "for images, labels in test_ds.unbatch().take(-1):\n",
    "    x_test.append(images.numpy())\n",
    "    y_test.append(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 4, 4, 4, 4, 4, 0, 0, 2, 4, 4, 1, 3, 2, 1, 0, 1, 1, 4, 4, 2,\n",
       "       1, 4, 3, 4, 1, 3, 4, 2, 3, 1, 3, 4, 3, 3, 2, 4, 4, 1, 2, 2, 3, 4,\n",
       "       2, 0, 0, 2, 1, 4, 4, 4, 4, 2, 4, 1, 4, 2, 1, 1, 2, 3, 2, 2, 2, 4,\n",
       "       2, 0, 2, 0, 2, 3, 0, 3, 0, 4, 1, 4, 3, 1, 4, 2, 1, 4, 4, 2, 4, 2,\n",
       "       1, 4, 4, 2, 2, 0, 0, 4, 3, 2, 3, 2, 2, 4, 4, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = np.array([np.count_nonzero(y_train ==0),np.count_nonzero(y_train ==1),np.count_nonzero(y_train ==2),np.count_nonzero(y_train ==3),np.count_nonzero(y_train ==4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dummy(y_train)\n",
    "y_test = dummy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 19, 26, 14, 34])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 256\n",
    "img_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "def create_weight(n_sample,n_class,n_class_sample):\n",
    "    weight = n_sample/(n_class*n_class_sample)\n",
    "    return weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0:0, 1:0,2:0,3:0,4:0}\n",
    "\n",
    "for i in range(num_classes):\n",
    "    class_weights[i]=create_weight(109,num_classes,class_count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.3625,\n",
       " 1: 1.1473684210526316,\n",
       " 2: 0.8384615384615385,\n",
       " 3: 1.5571428571428572,\n",
       " 4: 0.6411764705882353}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_3 (Rescaling)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " tf.cast_3 (TFOpLambda)      (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 8, 8, 2048)        23564800  \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 10245     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,575,045\n",
      "Trainable params: 10,245\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.ResNet50V2(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    ") \n",
    "\n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "scale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
    "x = scale_layer(inputs)\n",
    "\n",
    "x = tf.cast(x,tf.float32)\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "#x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = tf.keras.layers.Dense(5,activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" #model = tf.keras.Sequential([\\n            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\\n            tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\\n            tf.keras.layers.MaxPooling2D((2,2)),\\n            tf.keras.layers.Dropout(0.2),\\n            tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \\n            tf.keras.layers.MaxPooling2D((2,2)),\\n            tf.keras.layers.Dropout(0.2),\\n            tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\\n            tf.keras.layers.MaxPooling2D((2,2)),\\n            tf.keras.layers.Flatten(),\\n            tf.keras.layers.Dense(64, activation='relu'),\\n            tf.keras.layers.Dense(1, activation='sigmoid')\\n        ])\\nmodel.summary() \""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' #model = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "            tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2,2)),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \n",
    "            tf.keras.layers.MaxPooling2D((2,2)),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2,2)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "model.summary() '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet \n",
    "#inception v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()# modify weight in Adam\n",
    "metrics = ['accuracy']\n",
    "model.compile (optimizer = optimizer,loss =  loss_fn,metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 9s 3s/step - loss: 1.9959 - accuracy: 0.1842 - val_loss: 1.7494 - val_accuracy: 0.1212\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.7838 - accuracy: 0.2368 - val_loss: 1.6286 - val_accuracy: 0.1818\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.6221 - accuracy: 0.3026 - val_loss: 1.6111 - val_accuracy: 0.2424\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.5082 - accuracy: 0.3421 - val_loss: 1.5847 - val_accuracy: 0.2424\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.6109 - accuracy: 0.2368 - val_loss: 1.5349 - val_accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.4642 - accuracy: 0.3026 - val_loss: 1.4928 - val_accuracy: 0.3939\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.4942 - accuracy: 0.3684 - val_loss: 1.4513 - val_accuracy: 0.3939\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.3513 - accuracy: 0.5263 - val_loss: 1.4273 - val_accuracy: 0.4242\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.3438 - accuracy: 0.4605 - val_loss: 1.4156 - val_accuracy: 0.4242\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.3130 - accuracy: 0.4737 - val_loss: 1.4072 - val_accuracy: 0.4848\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.2731 - accuracy: 0.5789 - val_loss: 1.3991 - val_accuracy: 0.5152\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.2711 - accuracy: 0.5263 - val_loss: 1.3902 - val_accuracy: 0.5455\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.2746 - accuracy: 0.3684 - val_loss: 1.3679 - val_accuracy: 0.5455\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.1947 - accuracy: 0.4737 - val_loss: 1.3355 - val_accuracy: 0.5152\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.1337 - accuracy: 0.5789 - val_loss: 1.3143 - val_accuracy: 0.6061\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.1606 - accuracy: 0.5263 - val_loss: 1.3040 - val_accuracy: 0.5758\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.0767 - accuracy: 0.6579 - val_loss: 1.2932 - val_accuracy: 0.4848\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.1101 - accuracy: 0.5789 - val_loss: 1.2909 - val_accuracy: 0.4242\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.1259 - accuracy: 0.5921 - val_loss: 1.2803 - val_accuracy: 0.5455\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.1015 - accuracy: 0.6316 - val_loss: 1.2751 - val_accuracy: 0.5758\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.0666 - accuracy: 0.5263 - val_loss: 1.2692 - val_accuracy: 0.5455\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.0147 - accuracy: 0.6447 - val_loss: 1.2605 - val_accuracy: 0.5455\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9493 - accuracy: 0.6974 - val_loss: 1.2488 - val_accuracy: 0.5758\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.0239 - accuracy: 0.6579 - val_loss: 1.2374 - val_accuracy: 0.6061\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9757 - accuracy: 0.6579 - val_loss: 1.2203 - val_accuracy: 0.5758\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9602 - accuracy: 0.6842 - val_loss: 1.2100 - val_accuracy: 0.6061\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9838 - accuracy: 0.6711 - val_loss: 1.2147 - val_accuracy: 0.6061\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9198 - accuracy: 0.6711 - val_loss: 1.2112 - val_accuracy: 0.6061\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9569 - accuracy: 0.6711 - val_loss: 1.2023 - val_accuracy: 0.6061\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9201 - accuracy: 0.6842 - val_loss: 1.1879 - val_accuracy: 0.6061\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9312 - accuracy: 0.6447 - val_loss: 1.1779 - val_accuracy: 0.6061\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.8888 - accuracy: 0.7500 - val_loss: 1.1688 - val_accuracy: 0.6061\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.8015 - accuracy: 0.7895 - val_loss: 1.1634 - val_accuracy: 0.5152\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9105 - accuracy: 0.6447 - val_loss: 1.1563 - val_accuracy: 0.5152\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.8974 - accuracy: 0.6842 - val_loss: 1.1569 - val_accuracy: 0.5455\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.8395 - accuracy: 0.7500 - val_loss: 1.1522 - val_accuracy: 0.6364\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.8215 - accuracy: 0.7763 - val_loss: 1.1536 - val_accuracy: 0.6364\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.8463 - accuracy: 0.7237 - val_loss: 1.1606 - val_accuracy: 0.6364\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7677 - accuracy: 0.7763 - val_loss: 1.1487 - val_accuracy: 0.6364\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.8776 - accuracy: 0.6842 - val_loss: 1.1352 - val_accuracy: 0.6364\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7733 - accuracy: 0.7763 - val_loss: 1.1277 - val_accuracy: 0.6061\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7825 - accuracy: 0.8026 - val_loss: 1.1197 - val_accuracy: 0.6061\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7554 - accuracy: 0.8158 - val_loss: 1.1172 - val_accuracy: 0.5758\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.8158 - accuracy: 0.6974 - val_loss: 1.1133 - val_accuracy: 0.5758\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.7365 - accuracy: 0.8289 - val_loss: 1.1160 - val_accuracy: 0.5455\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.7608 - accuracy: 0.7237 - val_loss: 1.1241 - val_accuracy: 0.5758\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.7668 - accuracy: 0.7368 - val_loss: 1.1238 - val_accuracy: 0.5455\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.7351 - accuracy: 0.7763 - val_loss: 1.1153 - val_accuracy: 0.6364\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.7214 - accuracy: 0.7500 - val_loss: 1.0996 - val_accuracy: 0.6364\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6923 - accuracy: 0.8158 - val_loss: 1.0889 - val_accuracy: 0.6364\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.7432 - accuracy: 0.7763 - val_loss: 1.0896 - val_accuracy: 0.6364\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.7609 - accuracy: 0.7763 - val_loss: 1.0932 - val_accuracy: 0.6061\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.7166 - accuracy: 0.7632 - val_loss: 1.0887 - val_accuracy: 0.5455\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.6634 - accuracy: 0.8684 - val_loss: 1.0771 - val_accuracy: 0.6061\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 7s 3s/step - loss: 0.7049 - accuracy: 0.8158 - val_loss: 1.0662 - val_accuracy: 0.5758\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 8s 3s/step - loss: 0.6789 - accuracy: 0.7895 - val_loss: 1.0590 - val_accuracy: 0.5455\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 8s 3s/step - loss: 0.6829 - accuracy: 0.8158 - val_loss: 1.0609 - val_accuracy: 0.6364\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 7s 3s/step - loss: 0.6408 - accuracy: 0.8289 - val_loss: 1.0722 - val_accuracy: 0.5758\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.5912 - accuracy: 0.8421 - val_loss: 1.0802 - val_accuracy: 0.5758\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.6748 - accuracy: 0.7895 - val_loss: 1.0753 - val_accuracy: 0.5455\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.6762 - accuracy: 0.8026 - val_loss: 1.0625 - val_accuracy: 0.5152\n"
     ]
    }
   ],
   "source": [
    "# Set the epocks\n",
    "# ทำ stop + validation\n",
    "epochs = 100\n",
    "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,callbacks=callback,class_weight = class_weights)\n",
    "\n",
    "#history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_3 (Rescaling)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " tf.cast_3 (TFOpLambda)      (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 8, 8, 2048)        23564800  \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 10245     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,575,045\n",
      "Trainable params: 23,529,605\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 25s 7s/step - loss: 0.7600 - binary_accuracy: 0.9000 - val_loss: 1.4435 - val_binary_accuracy: 0.7939\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 20s 6s/step - loss: 0.6817 - binary_accuracy: 0.8842 - val_loss: 1.1204 - val_binary_accuracy: 0.8121\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 20s 6s/step - loss: 0.3276 - binary_accuracy: 0.9526 - val_loss: 1.1513 - val_binary_accuracy: 0.8242\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 20s 6s/step - loss: 0.3429 - binary_accuracy: 0.9605 - val_loss: 1.0543 - val_binary_accuracy: 0.8364\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 20s 6s/step - loss: 0.2497 - binary_accuracy: 0.9868 - val_loss: 1.0251 - val_binary_accuracy: 0.8242\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 20s 6s/step - loss: 0.1494 - binary_accuracy: 0.9868 - val_loss: 1.0961 - val_binary_accuracy: 0.8424\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 20s 6s/step - loss: 0.1592 - binary_accuracy: 0.9842 - val_loss: 1.0146 - val_binary_accuracy: 0.8424\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 20s 6s/step - loss: 0.0595 - binary_accuracy: 0.9947 - val_loss: 1.0065 - val_binary_accuracy: 0.8424\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 20s 6s/step - loss: 0.0330 - binary_accuracy: 1.0000 - val_loss: 1.0347 - val_binary_accuracy: 0.8545\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 20s 6s/step - loss: 0.0440 - binary_accuracy: 1.0000 - val_loss: 1.0151 - val_binary_accuracy: 0.8364\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 20s 6s/step - loss: 0.0351 - binary_accuracy: 1.0000 - val_loss: 1.0178 - val_binary_accuracy: 0.8606\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 20s 6s/step - loss: 0.0165 - binary_accuracy: 1.0000 - val_loss: 1.0227 - val_binary_accuracy: 0.8606\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 20s 6s/step - loss: 0.0209 - binary_accuracy: 1.0000 - val_loss: 1.0643 - val_binary_accuracy: 0.8727\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 50\n",
    "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,callbacks=callback,class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "actual = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 4, 4, 0, 4, 3, 1, 0, 0, 4, 0, 0, 2, 3, 0, 3, 2, 0, 1, 4, 2,\n",
       "       4, 2, 1, 4, 2, 1, 4, 4, 4, 4, 4, 2, 2, 1, 2, 4, 4, 4, 1, 2, 4, 2,\n",
       "       1, 0, 4, 2, 1, 4, 2, 1, 4, 0, 3, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3, 3, 0, 4, 4, 1, 4, 1, 4, 0, 0, 2, 2, 2, 2, 2, 0, 1, 3, 2,\n",
       "       4, 2, 4, 3, 2, 3, 4, 1, 4, 4, 2, 1, 1, 1, 2, 4, 3, 4, 0, 4, 4, 2,\n",
       "       1, 0, 4, 0, 1, 4, 2, 0, 4, 0, 3, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-498de5f81bc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \"\"\"\n\u001b[1;32m-> 1195\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56         9\n",
      "           1       0.62      0.50      0.56        10\n",
      "           2       0.53      0.69      0.60        13\n",
      "           3       0.33      0.38      0.35         8\n",
      "           4       0.57      0.47      0.52        17\n",
      "\n",
      "    accuracy                           0.53        57\n",
      "   macro avg       0.52      0.52      0.52        57\n",
      "weighted avg       0.54      0.53      0.53        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23bf0724a01b6ea9814e66f76182ea78c0ee849a72ca257c0e116bf83bb4960a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
