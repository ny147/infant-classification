{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ny147/infant-classification/blob/pete/train_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cpHscK9W4KEd",
        "outputId": "32ec61dd-e9d5-4b79-d88e-32636be490d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa, librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import shutil\n",
        "#import ftransc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Colab"
      ],
      "metadata": {
        "id": "kvNMNbwc5MmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/Infant_cry\"\n",
        "train_directory = path + '/mel_spectrogram/train_oneclass/hungry_one'\n",
        "test_directory = path + '/mel_spectrogram/test_oneclass/hungry_one'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1P1SA9q4LFI",
        "outputId": "2218106d-d503-4fef-e8f1-c59767b122ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local "
      ],
      "metadata": {
        "id": "k1BjHEUS5uZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_directory = path + '/data_matlab/train/'\n",
        "# test_directory = path + '/data_matlab/test/'"
      ],
      "metadata": {
        "id": "R3-uUE3m5rWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FDsbZ0NX4KEg",
        "outputId": "6961c691-ba40-4a89-d239-7db592d57bd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 303 files belonging to 2 classes.\n",
            "Found 154 files belonging to 2 classes.\n",
            "['hungry', 'non_hungry']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_directory, labels='inferred', label_mode='int', image_size=(256, 256), seed=321,\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_directory, labels='inferred', label_mode='int', image_size=(256, 256),\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hMp3ZErr4KEi"
      },
      "outputs": [],
      "source": [
        "## create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WRnYz0BQ4KEi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SGjcs6ok4KEj"
      },
      "outputs": [],
      "source": [
        "x_train=[]\n",
        "y_train=[]\n",
        "for images, labels in train_ds.unbatch().take(-1):\n",
        "    x_train.append(images.numpy())\n",
        "    y_train.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "52Syhv1s4KEj"
      },
      "outputs": [],
      "source": [
        "x_test=[]\n",
        "y_test=[]\n",
        "for images, labels in test_ds.unbatch().take(-1):\n",
        "    x_test.append(images.numpy())\n",
        "    y_test.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pTeqzMX54KEk"
      },
      "outputs": [],
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KuLx5bbv4KEk"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "def create_weight(n_sample,n_class,n_class_sample):\n",
        "    weight = n_sample/(n_class*n_class_sample)\n",
        "    return weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_PLcfLrI4KEl"
      },
      "outputs": [],
      "source": [
        "class_weights = {0:0, 1:0}\n",
        "class_count = np.array([255,51])\n",
        "for i in range(num_classes):\n",
        "    class_weights[i]=create_weight(306,num_classes,class_count[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CXXvqKtk4KEl",
        "outputId": "4ad2c7cc-4772-4d73-8841-7896988ceb40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 0s 0us/step\n",
            "83697664/83683744 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " tf.cast (TFOpLambda)        (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " xception (Functional)       (None, 8, 8, 2048)        20861480  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2049      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,863,529\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.applications.Xception(\n",
        "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(img_height, img_width, 3),\n",
        "    include_top=False,\n",
        ")  # Do not include the ImageNet classifier at the top.\n",
        "\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create new model on top\n",
        "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "#x = data_augmentation(inputs)  # Apply random data augmentation\n",
        "\n",
        "# Pre-trained Xception weights requires that input be scaled\n",
        "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
        "# outputs: `(inputs * scale) + offset`\n",
        "scale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
        "x = scale_layer(inputs)\n",
        "\n",
        "x = tf.cast(x,tf.float32)\n",
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "# x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(1)(x)\n",
        "outputs = tf.keras.layers.Activation('sigmoid')(outputs)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5mS95CLp4KEm",
        "outputId": "ef149d55-8b4a-418d-b578-14d67dc3fa2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_1 (Rescaling)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 256, 256, 256)     7168      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 128, 128, 256)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 128, 128, 128)     295040    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 64, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 64, 64, 16)        18448     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 32, 32, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                1048640   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,369,361\n",
            "Trainable params: 1,369,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "            tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ENIr5nXA4KEn"
      },
      "outputs": [],
      "source": [
        "#resnet \n",
        "#inception v3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LFN82DO_jX6j"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B-6CMHob4KEo"
      },
      "outputs": [],
      "source": [
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 8)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam()# modify weight in Adam\n",
        "metrics = ['accuracy']\n",
        "model.compile (optimizer = optimizer,loss =  loss_fn,metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2I_oiDJ94KEo",
        "outputId": "56a85567-2881-4ca6-d9ce-ebd13f5c1a18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 20s 879ms/step - loss: 1.0384 - accuracy: 0.4528 - val_loss: 0.6939 - val_accuracy: 0.1648\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.6829 - accuracy: 0.1651 - val_loss: 0.6953 - val_accuracy: 0.1648\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - 2s 360ms/step - loss: 0.6828 - accuracy: 0.1604 - val_loss: 0.6951 - val_accuracy: 0.1648\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - 2s 359ms/step - loss: 0.7011 - accuracy: 0.5660 - val_loss: 0.6950 - val_accuracy: 0.1648\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - 2s 360ms/step - loss: 0.6828 - accuracy: 0.1604 - val_loss: 0.6946 - val_accuracy: 0.1648\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - 2s 358ms/step - loss: 0.6825 - accuracy: 0.1604 - val_loss: 0.6952 - val_accuracy: 0.1648\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - 2s 360ms/step - loss: 0.6822 - accuracy: 0.5708 - val_loss: 0.6952 - val_accuracy: 0.2308\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - 3s 409ms/step - loss: 0.6817 - accuracy: 0.6462 - val_loss: 0.6864 - val_accuracy: 0.7582\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - 2s 359ms/step - loss: 0.6785 - accuracy: 0.8208 - val_loss: 0.6746 - val_accuracy: 0.7912\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - 2s 360ms/step - loss: 0.6677 - accuracy: 0.6368 - val_loss: 0.4932 - val_accuracy: 0.8352\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - 2s 357ms/step - loss: 0.7142 - accuracy: 0.5142 - val_loss: 0.7320 - val_accuracy: 0.2967\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - 2s 358ms/step - loss: 0.6633 - accuracy: 0.6745 - val_loss: 0.7363 - val_accuracy: 0.2637\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - 2s 357ms/step - loss: 0.6698 - accuracy: 0.2358 - val_loss: 0.7180 - val_accuracy: 0.3187\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - 2s 359ms/step - loss: 0.6592 - accuracy: 0.4198 - val_loss: 0.6580 - val_accuracy: 0.6374\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - 2s 359ms/step - loss: 0.6340 - accuracy: 0.7217 - val_loss: 0.6812 - val_accuracy: 0.5495\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.6036 - accuracy: 0.5236 - val_loss: 0.6902 - val_accuracy: 0.5055\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - 2s 358ms/step - loss: 0.5814 - accuracy: 0.4481 - val_loss: 0.6280 - val_accuracy: 0.6044\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - 2s 359ms/step - loss: 0.5429 - accuracy: 0.7783 - val_loss: 0.5557 - val_accuracy: 0.7363\n"
          ]
        }
      ],
      "source": [
        "# Set the epocks\n",
        "# ทำ stop + validation\n",
        "epochs = 30\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights,callbacks = [earlystop_callback])\n",
        "\n",
        "#history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "G9oorLuK4KEo",
        "outputId": "6461bef0-c1bf-4741-b5ba-4d99c3f4c862",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_1 (Rescaling)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 256, 256, 256)     7168      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 128, 128, 256)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 128, 128, 128)     295040    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 64, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 64, 64, 16)        18448     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 32, 32, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                1048640   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,369,361\n",
            "Trainable params: 1,369,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 3s 397ms/step - loss: 0.4564 - binary_accuracy: 0.7877 - val_loss: 0.5589 - val_binary_accuracy: 0.7363\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.4608 - binary_accuracy: 0.7972 - val_loss: 0.5613 - val_binary_accuracy: 0.7253\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 2s 360ms/step - loss: 0.4536 - binary_accuracy: 0.8019 - val_loss: 0.5635 - val_binary_accuracy: 0.7253\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.4504 - binary_accuracy: 0.7877 - val_loss: 0.5649 - val_binary_accuracy: 0.7253\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 2s 359ms/step - loss: 0.4626 - binary_accuracy: 0.7972 - val_loss: 0.5664 - val_binary_accuracy: 0.7143\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 2s 361ms/step - loss: 0.4436 - binary_accuracy: 0.7783 - val_loss: 0.5688 - val_binary_accuracy: 0.7033\n",
            "Epoch 7/15\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.4523 - binary_accuracy: 0.7972 - val_loss: 0.5708 - val_binary_accuracy: 0.7033\n",
            "Epoch 8/15\n",
            "7/7 [==============================] - 2s 361ms/step - loss: 0.4466 - binary_accuracy: 0.8113 - val_loss: 0.5727 - val_binary_accuracy: 0.7033\n",
            "Epoch 9/15\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.4525 - binary_accuracy: 0.7925 - val_loss: 0.5747 - val_binary_accuracy: 0.6923\n"
          ]
        }
      ],
      "source": [
        "base_model.trainable = True\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 15\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,callbacks = [earlystop_callback],class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cQ7QKhSO4KEp"
      },
      "outputs": [],
      "source": [
        "def binary_transform(pred):\n",
        "    if pred > 0.5:\n",
        "        predicted = 1\n",
        "    else:\n",
        "        predicted = 0\n",
        "    return predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NTHyhXUb4KEp"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(x_test)\n",
        "\n",
        "vfunc = np.vectorize(binary_transform)\n",
        "y_pred = vfunc(pred)\n",
        "actual = x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "a3MuHsl24KEp",
        "outputId": "44cba768-6354-4ad6-a180-46699a7b3995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=class_names)\n",
        "disp.plot()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xsWVsk_w4KEq",
        "outputId": "3acfb8ab-f5fb-45a0-a62e-d98effda29a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Hungry       0.90      0.70      0.79       128\n",
            "  Non_hungry       0.30      0.62      0.40        26\n",
            "\n",
            "    accuracy                           0.69       154\n",
            "   macro avg       0.60      0.66      0.59       154\n",
            "weighted avg       0.80      0.69      0.72       154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred,target_names=[\"Hungry\",\"Non_hungry\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SbdIq4kD4KEq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ISP_9AMdCIPb",
        "outputId": "b7b05c1b-21dd-4d3e-b370-9e6f5577daa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6153846153846154"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J-8B4TrACitT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "23bf0724a01b6ea9814e66f76182ea78c0ee849a72ca257c0e116bf83bb4960a"
      }
    },
    "colab": {
      "name": "train_evaluate.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}