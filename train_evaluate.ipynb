{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ny147/infant-classification/blob/pete/train_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "cpHscK9W4KEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4047470c-9bbe-4eae-9cb0-a69aedd1fc87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: focal_loss in /usr/local/lib/python3.7/dist-packages (0.0.7)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal_loss) (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (14.0.1)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.47.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.5.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (4.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.26.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.15.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal_loss) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2->focal_loss) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa, librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import shutil\n",
        "!pip install focal_loss\n",
        "from focal_loss import BinaryFocalLoss\n",
        "#import ftransc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Colab"
      ],
      "metadata": {
        "id": "kvNMNbwc5MmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/Infant_cry\"\n",
        "train_directory = path + '/mel_spectrogram/train_oneclass/hungry_one'\n",
        "test_directory = path + '/mel_spectrogram/test_oneclass/hungry_one'\n",
        "# Matlab data\n",
        "# train_directory = path + '/mfcc_matlab/train/'\n",
        "# test_directory = path + '/mfcc_matlab/test/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1P1SA9q4LFI",
        "outputId": "b9b92f94-7949-48e1-e80b-34da90ff22dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local "
      ],
      "metadata": {
        "id": "k1BjHEUS5uZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_directory = path + '/data_matlab/train/'\n",
        "# test_directory = path + '/data_matlab/test/'"
      ],
      "metadata": {
        "id": "R3-uUE3m5rWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FDsbZ0NX4KEg",
        "outputId": "f3fe7a8b-1344-47a9-809c-c24c66d6017b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 303 files belonging to 2 classes.\n",
            "Found 154 files belonging to 2 classes.\n",
            "['hungry', 'non_hungry']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_directory, labels='inferred', label_mode='int', image_size=(256, 256), seed=321,\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_directory, labels='inferred', label_mode='int', image_size=(256, 256),\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMp3ZErr4KEi"
      },
      "outputs": [],
      "source": [
        "## create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WRnYz0BQ4KEi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SGjcs6ok4KEj"
      },
      "outputs": [],
      "source": [
        "x_train=[]\n",
        "y_train=[]\n",
        "for images, labels in train_ds.unbatch().take(-1):\n",
        "    x_train.append(images.numpy())\n",
        "    y_train.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "52Syhv1s4KEj"
      },
      "outputs": [],
      "source": [
        "x_test=[]\n",
        "y_test=[]\n",
        "for images, labels in test_ds.unbatch().take(-1):\n",
        "    x_test.append(images.numpy())\n",
        "    y_test.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pTeqzMX54KEk"
      },
      "outputs": [],
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KuLx5bbv4KEk"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "def create_weight(n_sample,n_class,n_class_sample):\n",
        "    weight = n_sample/(n_class*n_class_sample)\n",
        "    return weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "_PLcfLrI4KEl"
      },
      "outputs": [],
      "source": [
        "class_weights = {0:0, 1:0}\n",
        "class_count = np.array([254,49])\n",
        "for i in range(num_classes):\n",
        "    class_weights[i]=create_weight(306,num_classes,class_count[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "CXXvqKtk4KEl",
        "outputId": "8eb40bc9-6517-4bf0-e46d-b0ec9a8b5e60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_3 (Rescaling)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " tf.cast_2 (TFOpLambda)      (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " vgg19 (Functional)          (None, 8, 8, 512)         20024384  \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,024,897\n",
            "Trainable params: 513\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# base_model = tf.keras.applications.Xception(\n",
        "#     weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     include_top=False,\n",
        "# )  # Do not include the ImageNet classifier at the top.\n",
        "\n",
        "# base_model = tf.keras.applications.ResNet50V2(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_tensor=None,\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     pooling=None,\n",
        "#     # classes=1000,\n",
        "#     classifier_activation=\"softmax\",\n",
        "# )\n",
        "# base_model = tf.keras.applications.InceptionResNetV2(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     pooling=None,\n",
        "#     classifier_activation=\"softmax\"\n",
        "# )\n",
        "\n",
        "base_model = tf.keras.applications.VGG19(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(img_height, img_width, 3),\n",
        "    pooling=None,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create new model on top\n",
        "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "#x = data_augmentation(inputs)  # Apply random data augmentation\n",
        "\n",
        "# Pre-trained Xception weights requires that input be scaled\n",
        "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
        "# outputs: `(inputs * scale) + offset`\n",
        "scale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
        "x = scale_layer(inputs)\n",
        "\n",
        "x = tf.cast(x,tf.float32)\n",
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "# x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(1)(x)\n",
        "outputs = tf.keras.layers.Activation('sigmoid')(outputs)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5mS95CLp4KEm"
      },
      "outputs": [],
      "source": [
        "# model = tf.keras.Sequential([\n",
        "#             tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "#             tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "#             tf.keras.layers.MaxPooling2D((2,2)),\n",
        "#             tf.keras.layers.Dropout(0.2),\n",
        "#             tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \n",
        "#             tf.keras.layers.MaxPooling2D((2,2)),\n",
        "#             tf.keras.layers.Dropout(0.2),\n",
        "#             tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "#             tf.keras.layers.MaxPooling2D((2,2)),\n",
        "#             tf.keras.layers.Flatten(),\n",
        "#             tf.keras.layers.Dense(64, activation='relu'),\n",
        "#             tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "#         ])\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ENIr5nXA4KEn"
      },
      "outputs": [],
      "source": [
        "#resnet \n",
        "#inception v3\n",
        "from focal_loss import BinaryFocalLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "B-6CMHob4KEo"
      },
      "outputs": [],
      "source": [
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 10)\n",
        "earlystop_callback2 = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy',patience = 10)\n",
        "# loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "loss_fn = BinaryFocalLoss(gamma=2)\n",
        "optimizer = tf.keras.optimizers.Adam()# modify weight in Adam\n",
        "metrics = ['accuracy']\n",
        "model.compile (optimizer = optimizer,loss =  loss_fn,metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "2I_oiDJ94KEo",
        "outputId": "e108f388-bb57-45bf-a6aa-7ad9d3a0f405",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 4s 362ms/step - loss: 0.2318 - accuracy: 0.2972 - val_loss: 0.1652 - val_accuracy: 0.6593\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.1939 - accuracy: 0.5802 - val_loss: 0.1613 - val_accuracy: 0.7363\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.1919 - accuracy: 0.5189 - val_loss: 0.1794 - val_accuracy: 0.3956\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.1772 - accuracy: 0.4764 - val_loss: 0.1790 - val_accuracy: 0.3956\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.1778 - accuracy: 0.4906 - val_loss: 0.1609 - val_accuracy: 0.7363\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.1849 - accuracy: 0.6179 - val_loss: 0.1539 - val_accuracy: 0.8242\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.1703 - accuracy: 0.6085 - val_loss: 0.1699 - val_accuracy: 0.5604\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.1982 - accuracy: 0.4811 - val_loss: 0.1810 - val_accuracy: 0.4066\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 2s 317ms/step - loss: 0.1963 - accuracy: 0.4623 - val_loss: 0.1654 - val_accuracy: 0.6374\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.1879 - accuracy: 0.5142 - val_loss: 0.1740 - val_accuracy: 0.4615\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.1908 - accuracy: 0.4717 - val_loss: 0.1783 - val_accuracy: 0.4396\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 2s 317ms/step - loss: 0.1831 - accuracy: 0.4151 - val_loss: 0.1812 - val_accuracy: 0.4176\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 2s 318ms/step - loss: 0.1862 - accuracy: 0.4623 - val_loss: 0.1638 - val_accuracy: 0.6703\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 2s 319ms/step - loss: 0.1835 - accuracy: 0.6462 - val_loss: 0.1524 - val_accuracy: 0.8242\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 2s 319ms/step - loss: 0.1795 - accuracy: 0.6038 - val_loss: 0.1661 - val_accuracy: 0.5934\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 2s 321ms/step - loss: 0.1751 - accuracy: 0.5943 - val_loss: 0.1725 - val_accuracy: 0.4835\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 2s 321ms/step - loss: 0.1741 - accuracy: 0.5283 - val_loss: 0.1696 - val_accuracy: 0.5275\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 2s 323ms/step - loss: 0.1756 - accuracy: 0.5236 - val_loss: 0.1633 - val_accuracy: 0.6703\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 2s 323ms/step - loss: 0.1776 - accuracy: 0.5660 - val_loss: 0.1643 - val_accuracy: 0.6374\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 2s 320ms/step - loss: 0.1720 - accuracy: 0.5047 - val_loss: 0.1698 - val_accuracy: 0.5165\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 2s 322ms/step - loss: 0.1696 - accuracy: 0.6085 - val_loss: 0.1590 - val_accuracy: 0.7582\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 2s 328ms/step - loss: 0.1742 - accuracy: 0.6179 - val_loss: 0.1543 - val_accuracy: 0.7912\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 2s 341ms/step - loss: 0.1791 - accuracy: 0.5755 - val_loss: 0.1642 - val_accuracy: 0.6044\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 2s 339ms/step - loss: 0.1754 - accuracy: 0.5000 - val_loss: 0.1727 - val_accuracy: 0.5165\n"
          ]
        }
      ],
      "source": [
        "# Set the epocks\n",
        "# ทำ stop + validation\n",
        "epochs = 50\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights,callbacks = [earlystop_callback,earlystop_callback2])\n",
        "# history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights)\n",
        "#history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "G9oorLuK4KEo",
        "outputId": "ddc5b805-bfa7-4c22-ae45-40a876ba816b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_3 (Rescaling)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " tf.cast_2 (TFOpLambda)      (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " vgg19 (Functional)          (None, 8, 8, 512)         20024384  \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,024,897\n",
            "Trainable params: 20,024,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "7/7 [==============================] - 6s 735ms/step - loss: 0.1821 - binary_accuracy: 0.5991 - val_loss: 0.1800 - val_binary_accuracy: 0.4066\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 5s 691ms/step - loss: 0.1761 - binary_accuracy: 0.5472 - val_loss: 0.1544 - val_binary_accuracy: 0.7692\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 5s 698ms/step - loss: 0.1601 - binary_accuracy: 0.5943 - val_loss: 0.1686 - val_binary_accuracy: 0.5385\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 5s 697ms/step - loss: 0.1466 - binary_accuracy: 0.6887 - val_loss: 0.1367 - val_binary_accuracy: 0.8352\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 5s 700ms/step - loss: 0.1467 - binary_accuracy: 0.8160 - val_loss: 0.1471 - val_binary_accuracy: 0.7143\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 5s 702ms/step - loss: 0.1344 - binary_accuracy: 0.7170 - val_loss: 0.1316 - val_binary_accuracy: 0.8132\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 5s 703ms/step - loss: 0.1196 - binary_accuracy: 0.8396 - val_loss: 0.1126 - val_binary_accuracy: 0.8681\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 5s 704ms/step - loss: 0.1147 - binary_accuracy: 0.7642 - val_loss: 0.1045 - val_binary_accuracy: 0.8901\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 5s 710ms/step - loss: 0.0936 - binary_accuracy: 0.9057 - val_loss: 0.1075 - val_binary_accuracy: 0.8242\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 5s 714ms/step - loss: 0.0732 - binary_accuracy: 0.9387 - val_loss: 0.1242 - val_binary_accuracy: 0.7143\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 5s 710ms/step - loss: 0.0583 - binary_accuracy: 0.9245 - val_loss: 0.0910 - val_binary_accuracy: 0.8791\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 5s 714ms/step - loss: 0.0479 - binary_accuracy: 0.9292 - val_loss: 0.1056 - val_binary_accuracy: 0.8462\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 5s 717ms/step - loss: 0.0431 - binary_accuracy: 0.9623 - val_loss: 0.0857 - val_binary_accuracy: 0.8901\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 5s 726ms/step - loss: 0.0229 - binary_accuracy: 0.9811 - val_loss: 0.0988 - val_binary_accuracy: 0.8901\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 5s 720ms/step - loss: 0.0251 - binary_accuracy: 0.9764 - val_loss: 0.1067 - val_binary_accuracy: 0.8681\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 5s 722ms/step - loss: 0.0399 - binary_accuracy: 0.9481 - val_loss: 0.1141 - val_binary_accuracy: 0.7582\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 5s 722ms/step - loss: 0.0386 - binary_accuracy: 0.9575 - val_loss: 0.1000 - val_binary_accuracy: 0.8571\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 5s 723ms/step - loss: 0.0220 - binary_accuracy: 0.9670 - val_loss: 0.1375 - val_binary_accuracy: 0.8352\n"
          ]
        }
      ],
      "source": [
        "earlystop_callback2 = tf.keras.callbacks.EarlyStopping(monitor = 'binary_accuracy',patience = 4,min_delta=0)\n",
        "base_model.trainable = True\n",
        "model.summary()\n",
        "# loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss = loss_fn,\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,callbacks = [earlystop_callback,earlystop_callback2],class_weight = class_weights)\n",
        "# history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "cQ7QKhSO4KEp"
      },
      "outputs": [],
      "source": [
        "def binary_transform(pred):\n",
        "    if pred > 0.5:\n",
        "        predicted = 1\n",
        "    else:\n",
        "        predicted = 0\n",
        "    return predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "NTHyhXUb4KEp"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(x_test)\n",
        "\n",
        "vfunc = np.vectorize(binary_transform)\n",
        "y_pred = vfunc(pred)\n",
        "actual = x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "a3MuHsl24KEp",
        "outputId": "2e4471af-9769-4651-d869-c158a535de1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=class_names)\n",
        "disp.plot()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "xsWVsk_w4KEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69efe264-6c49-493d-aa6a-89653e45da3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Hungry       0.83      0.91      0.87       128\n",
            "  Non_hungry       0.15      0.08      0.10        26\n",
            "\n",
            "    accuracy                           0.77       154\n",
            "   macro avg       0.49      0.50      0.49       154\n",
            "weighted avg       0.72      0.77      0.74       154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred,target_names=[\"Hungry\",\"Non_hungry\"]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MICls6lpDG0E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "23bf0724a01b6ea9814e66f76182ea78c0ee849a72ca257c0e116bf83bb4960a"
      }
    },
    "colab": {
      "name": "train_evaluate.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}