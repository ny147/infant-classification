{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ny147/infant-classification/blob/pete/train_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cpHscK9W4KEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32ec61dd-e9d5-4b79-d88e-32636be490d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa, librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import shutil\n",
        "#import ftransc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Colab"
      ],
      "metadata": {
        "id": "kvNMNbwc5MmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/Infant_cry\"\n",
        "train_directory = path + '/mel_spectrogram/train_oneclass/hungry_one'\n",
        "test_directory = path + '/mel_spectrogram/test_oneclass/hungry_one'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1P1SA9q4LFI",
        "outputId": "2218106d-d503-4fef-e8f1-c59767b122ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local "
      ],
      "metadata": {
        "id": "k1BjHEUS5uZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_directory = path + '/data_matlab/train/'\n",
        "# test_directory = path + '/data_matlab/test/'"
      ],
      "metadata": {
        "id": "R3-uUE3m5rWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FDsbZ0NX4KEg",
        "outputId": "6961c691-ba40-4a89-d239-7db592d57bd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 303 files belonging to 2 classes.\n",
            "Found 154 files belonging to 2 classes.\n",
            "['hungry', 'non_hungry']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_directory, labels='inferred', label_mode='int', image_size=(256, 256), seed=321,\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_directory, labels='inferred', label_mode='int', image_size=(256, 256),\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hMp3ZErr4KEi"
      },
      "outputs": [],
      "source": [
        "## create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WRnYz0BQ4KEi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SGjcs6ok4KEj"
      },
      "outputs": [],
      "source": [
        "x_train=[]\n",
        "y_train=[]\n",
        "for images, labels in train_ds.unbatch().take(-1):\n",
        "    x_train.append(images.numpy())\n",
        "    y_train.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "52Syhv1s4KEj"
      },
      "outputs": [],
      "source": [
        "x_test=[]\n",
        "y_test=[]\n",
        "for images, labels in test_ds.unbatch().take(-1):\n",
        "    x_test.append(images.numpy())\n",
        "    y_test.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pTeqzMX54KEk"
      },
      "outputs": [],
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KuLx5bbv4KEk"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "def create_weight(n_sample,n_class,n_class_sample):\n",
        "    weight = n_sample/(n_class*n_class_sample)\n",
        "    return weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_PLcfLrI4KEl"
      },
      "outputs": [],
      "source": [
        "class_weights = {0:0, 1:0}\n",
        "class_count = np.array([254,49])\n",
        "for i in range(num_classes):\n",
        "    class_weights[i]=create_weight(306,num_classes,class_count[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "CXXvqKtk4KEl",
        "outputId": "66469ad6-57c8-4e84-f2a0-5f0033e1e6a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_26 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_30 (Rescaling)    (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " tf.cast_12 (TFOpLambda)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " inception_resnet_v2 (Functi  (None, 6, 6, 1536)       54336736  \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " global_average_pooling2d_12  (None, 1536)             0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 1536)              0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 1)                 1537      \n",
            "                                                                 \n",
            " activation_1026 (Activation  (None, 1)                0         \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,338,273\n",
            "Trainable params: 1,537\n",
            "Non-trainable params: 54,336,736\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# base_model = tf.keras.applications.Xception(\n",
        "#     weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     include_top=False,\n",
        "# )  # Do not include the ImageNet classifier at the top.\n",
        "\n",
        "# base_model = tf.keras.applications.ResNet50V2(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_tensor=None,\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     pooling=None,\n",
        "#     # classes=1000,\n",
        "#     classifier_activation=\"softmax\",\n",
        "# )\n",
        "base_model = tf.keras.applications.InceptionResNetV2(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(img_height, img_width, 3),\n",
        "    pooling=None,\n",
        "    classifier_activation=\"softmax\"\n",
        ")\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create new model on top\n",
        "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "#x = data_augmentation(inputs)  # Apply random data augmentation\n",
        "\n",
        "# Pre-trained Xception weights requires that input be scaled\n",
        "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
        "# outputs: `(inputs * scale) + offset`\n",
        "scale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
        "x = scale_layer(inputs)\n",
        "\n",
        "x = tf.cast(x,tf.float32)\n",
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "# x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(1)(x)\n",
        "outputs = tf.keras.layers.Activation('sigmoid')(outputs)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "5mS95CLp4KEm",
        "outputId": "53563db4-0eae-4621-c993-462a7ba6bf2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_32 (Rescaling)    (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d_1088 (Conv2D)        (None, 256, 256, 256)     7168      \n",
            "                                                                 \n",
            " max_pooling2d_82 (MaxPoolin  (None, 128, 128, 256)    0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " conv2d_1089 (Conv2D)        (None, 128, 128, 128)     295040    \n",
            "                                                                 \n",
            " max_pooling2d_83 (MaxPoolin  (None, 64, 64, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_1090 (Conv2D)        (None, 64, 64, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_84 (MaxPoolin  (None, 32, 32, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_19 (Flatten)        (None, 65536)             0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 64)                4194368   \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,570,433\n",
            "Trainable params: 4,570,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "            tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "ENIr5nXA4KEn"
      },
      "outputs": [],
      "source": [
        "#resnet \n",
        "#inception v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "B-6CMHob4KEo"
      },
      "outputs": [],
      "source": [
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 15)\n",
        "earlystop_callback2 = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy',patience = 15)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam()# modify weight in Adam\n",
        "metrics = ['accuracy']\n",
        "model.compile (optimizer = optimizer,loss =  loss_fn,metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "2I_oiDJ94KEo",
        "outputId": "d5029f92-8995-4481-b0f7-331c86455719",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 3s 398ms/step - loss: 1.5252 - accuracy: 0.6038 - val_loss: 0.6994 - val_accuracy: 0.1648\n",
            "Epoch 2/40\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.6995 - accuracy: 0.1604 - val_loss: 0.6989 - val_accuracy: 0.1648\n",
            "Epoch 3/40\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.6979 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.3626\n",
            "Epoch 4/40\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.7528 - accuracy: 0.7170 - val_loss: 0.6948 - val_accuracy: 0.2637\n",
            "Epoch 5/40\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.6956 - accuracy: 0.3726 - val_loss: 0.6955 - val_accuracy: 0.3297\n",
            "Epoch 6/40\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.6938 - accuracy: 0.7170 - val_loss: 0.6919 - val_accuracy: 0.4615\n",
            "Epoch 7/40\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.6805 - accuracy: 0.5991 - val_loss: 0.6488 - val_accuracy: 0.7143\n",
            "Epoch 8/40\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.6777 - accuracy: 0.7358 - val_loss: 0.7008 - val_accuracy: 0.4066\n",
            "Epoch 9/40\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.6557 - accuracy: 0.4292 - val_loss: 0.6500 - val_accuracy: 0.5824\n",
            "Epoch 10/40\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.6207 - accuracy: 0.6887 - val_loss: 0.5853 - val_accuracy: 0.6374\n",
            "Epoch 11/40\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.5761 - accuracy: 0.6792 - val_loss: 0.7256 - val_accuracy: 0.5385\n",
            "Epoch 12/40\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.5224 - accuracy: 0.7453 - val_loss: 0.5492 - val_accuracy: 0.6593\n",
            "Epoch 13/40\n",
            "7/7 [==============================] - 3s 368ms/step - loss: 0.4468 - accuracy: 0.7123 - val_loss: 0.6509 - val_accuracy: 0.6484\n",
            "Epoch 14/40\n",
            "7/7 [==============================] - 3s 372ms/step - loss: 0.4242 - accuracy: 0.7358 - val_loss: 0.6002 - val_accuracy: 0.6593\n",
            "Epoch 15/40\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.3496 - accuracy: 0.7877 - val_loss: 0.7053 - val_accuracy: 0.6593\n",
            "Epoch 16/40\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.3256 - accuracy: 0.8491 - val_loss: 0.7207 - val_accuracy: 0.6593\n",
            "Epoch 17/40\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 0.3325 - accuracy: 0.8113 - val_loss: 0.7548 - val_accuracy: 0.6593\n",
            "Epoch 18/40\n",
            "7/7 [==============================] - 3s 368ms/step - loss: 0.2552 - accuracy: 0.8491 - val_loss: 0.5985 - val_accuracy: 0.7363\n",
            "Epoch 19/40\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 0.2375 - accuracy: 0.8255 - val_loss: 0.5580 - val_accuracy: 0.7363\n",
            "Epoch 20/40\n",
            "7/7 [==============================] - 3s 368ms/step - loss: 0.1728 - accuracy: 0.9481 - val_loss: 0.5969 - val_accuracy: 0.7582\n",
            "Epoch 21/40\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 0.1500 - accuracy: 0.8915 - val_loss: 0.6903 - val_accuracy: 0.7473\n",
            "Epoch 22/40\n",
            "7/7 [==============================] - 3s 368ms/step - loss: 0.1109 - accuracy: 0.9623 - val_loss: 0.7149 - val_accuracy: 0.7802\n",
            "Epoch 23/40\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 0.0844 - accuracy: 0.9811 - val_loss: 0.8273 - val_accuracy: 0.7363\n",
            "Epoch 24/40\n",
            "7/7 [==============================] - 3s 368ms/step - loss: 0.0706 - accuracy: 0.9623 - val_loss: 0.7529 - val_accuracy: 0.7912\n",
            "Epoch 25/40\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 0.0503 - accuracy: 0.9764 - val_loss: 0.9572 - val_accuracy: 0.7802\n",
            "Epoch 26/40\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 0.0289 - accuracy: 0.9953 - val_loss: 1.3142 - val_accuracy: 0.7582\n",
            "Epoch 27/40\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 1.4808 - val_accuracy: 0.7802\n"
          ]
        }
      ],
      "source": [
        "# Set the epocks\n",
        "# ทำ stop + validation\n",
        "epochs = 40\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights,callbacks = [earlystop_callback,earlystop_callback2])\n",
        "\n",
        "#history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "G9oorLuK4KEo",
        "outputId": "a5c8b564-eb2b-406e-9e12-d4bb5c7b1869",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_32 (Rescaling)    (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d_1088 (Conv2D)        (None, 256, 256, 256)     7168      \n",
            "                                                                 \n",
            " max_pooling2d_82 (MaxPoolin  (None, 128, 128, 256)    0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " conv2d_1089 (Conv2D)        (None, 128, 128, 128)     295040    \n",
            "                                                                 \n",
            " max_pooling2d_83 (MaxPoolin  (None, 64, 64, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_1090 (Conv2D)        (None, 64, 64, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_84 (MaxPoolin  (None, 32, 32, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_19 (Flatten)        (None, 65536)             0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 64)                4194368   \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,570,433\n",
            "Trainable params: 4,570,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 3s 402ms/step - loss: 0.0077 - binary_accuracy: 1.0000 - val_loss: 1.4525 - val_binary_accuracy: 0.7692\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 0.0081 - binary_accuracy: 1.0000 - val_loss: 1.4310 - val_binary_accuracy: 0.7692\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 0.0100 - binary_accuracy: 0.9953 - val_loss: 1.4157 - val_binary_accuracy: 0.7802\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - 3s 371ms/step - loss: 0.0099 - binary_accuracy: 1.0000 - val_loss: 1.4019 - val_binary_accuracy: 0.7802\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 0.0069 - binary_accuracy: 1.0000 - val_loss: 1.3933 - val_binary_accuracy: 0.7802\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 0.0073 - binary_accuracy: 1.0000 - val_loss: 1.3836 - val_binary_accuracy: 0.7802\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 0.0049 - binary_accuracy: 1.0000 - val_loss: 1.3775 - val_binary_accuracy: 0.7802\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 0.0053 - binary_accuracy: 1.0000 - val_loss: 1.3748 - val_binary_accuracy: 0.7802\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 0.0062 - binary_accuracy: 1.0000 - val_loss: 1.3708 - val_binary_accuracy: 0.7802\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 0.0066 - binary_accuracy: 1.0000 - val_loss: 1.3713 - val_binary_accuracy: 0.7802\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - 3s 368ms/step - loss: 0.0051 - binary_accuracy: 1.0000 - val_loss: 1.3743 - val_binary_accuracy: 0.7802\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 0.0051 - binary_accuracy: 1.0000 - val_loss: 1.3764 - val_binary_accuracy: 0.7802\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 0.0064 - binary_accuracy: 1.0000 - val_loss: 1.3760 - val_binary_accuracy: 0.7802\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - 3s 372ms/step - loss: 0.0042 - binary_accuracy: 1.0000 - val_loss: 1.3813 - val_binary_accuracy: 0.7802\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - 3s 368ms/step - loss: 0.0055 - binary_accuracy: 1.0000 - val_loss: 1.3851 - val_binary_accuracy: 0.7802\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 0.0058 - binary_accuracy: 1.0000 - val_loss: 1.3870 - val_binary_accuracy: 0.7802\n"
          ]
        }
      ],
      "source": [
        "earlystop_callback2 = tf.keras.callbacks.EarlyStopping(monitor = 'binary_accuracy',patience = 15)\n",
        "base_model.trainable = True\n",
        "model.summary()\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 30\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,callbacks = [earlystop_callback,earlystop_callback2],class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "cQ7QKhSO4KEp"
      },
      "outputs": [],
      "source": [
        "def binary_transform(pred):\n",
        "    if pred > 0.5:\n",
        "        predicted = 1\n",
        "    else:\n",
        "        predicted = 0\n",
        "    return predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "NTHyhXUb4KEp"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(x_test)\n",
        "\n",
        "vfunc = np.vectorize(binary_transform)\n",
        "y_pred = vfunc(pred)\n",
        "actual = x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "id": "a3MuHsl24KEp",
        "outputId": "fdbe1c8a-dd06-4e69-fb08-842df2f70539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {},
          "execution_count": 237
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEHCAYAAABlbhceAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdd0lEQVR4nO3de7xVdZ3/8debAwQoCAgSKop3U1EyItR0CNTS8TFmmtT4MzQbyhwrrUfSxZxxuqjZWGbqICWY2igpaWZeE8u8IOAlBRUGEVRUbqIgKOzz+f2x1pHt8XDOOpuzz95r7/fz8dgP1uW71/rscw6f9d3f9V3fryICMzPLhy6VDsDMzLJz0jYzyxEnbTOzHHHSNjPLESdtM7Mc6VrpAGrZgP4NMXRIt0qHYe0wf27vSodg7fTGxuXLI2Lglhzjk5/YKlasLGQqO/vJt++MiE9tyfm2hJN2GQ0d0o2Zdw6pdBjWDkcPG1PpEKyd7lw+6YUtPcaKlQVm3rlTprINg+cP2NLzbQknbTOrewE00ljpMDJx0jazuhcEGyJb80ilOWmbmeGatplZbgRBISdDejhpm5kBjThpm5nlQgAFJ20zs/xwTdvMLCcC2OA2bTOzfAjCzSNmZrkRUMhHznbSNjNLnojMBydtMzNEAVU6iEyctM2s7gXQ6OYRM7N8COCdnEwv4KRtZgY0hptHzMxyIXki0knbzCwXAlFw84iZWX64ecTMLCcC8U40VDqMTJy0zazuJQ/XuHnEzCw3fCPSzCwnIkQhXNM2M8uNRte0zczyIemn7Zq2mVkuBGJD5CMd5iNKM7MyK7iftplZPuTpich8RGlmVmaN0SXTqy2SfiPpNUlPFW3rL+luSfPTf/ul2yXpUkkLJD0p6cC2ju+kbWZ1r+lGZJZXBlOATzXbNhG4NyL2AO5N1wGOAvZIXxOAK9o6uJO2mdW9QBQi26vNY0X8FVjZbPOxwNR0eSrw6aLt10TiYaCvpMGtHd9t2mZW9yJoT++RAZJmFa1PiohJbbxnUEQsTZdfAQalyzsAS4rKvZhuW8pmOGmbmaH2PFyzPCJGlHqmiAhJJU9u5qRtZnUvoNyPsb8qaXBELE2bP15Lt78EDCkqt2O6bbPcpm1mRofeiGzJrcD4dHk8cEvR9i+kvUhGAauLmlFa5Jq2mdW9QB02CYKk3wGjSdq+XwTOAy4AbpR0GvACcGJa/HbgaGAB8BZwalvHd9I2s7oXtOtGZOvHivj8ZnaNbaFsAGe05/hO2mZmyONpm5nlRUCmpx2rgZO2mRmeucbMLDci5Jq2mVmeeLoxM7OcSCZBaKh0GJk4aZtZ3UtuRLpN28wsN/IyCYKTtpnVvY58IrLcnLTNzIBG17TNzPIhwhP7mpnlRiA2Nrr3iJlZbviJSMutn501hEfu6UPfARuZdN+zAPz1j9vw2599kCXze3Dp7c+x5wHr3i2/cG4PLj1nCGvf7EKXLvDL25+je4+SJ+awLfSN8+cx8rAVvL6yO1/9zEgAvnj2Aj42egUbN4ilS3pyybl7s/bNbhWOtHrkqctfPlreWyBpaPEU9dZxjhy3kh9dt/A924buvZ4fTF7EsFFr37O9sBEuOnNnzrxgCVfNeJaf/n4BDd2csCvpnlsGc+7pB7xn22MP9ef04z7KGceP5KUXenHilxZXKLpqlTzGnuVVaZWPICck1c23kmGj1tK7X+E923ba422G7P72+8rOvr83u3xoHbvtux6APv0LNOSjabBmPTW7L2+ufu+f62MP9aexkPx3f+aJPgwY9P7fZb1rTOeJbOtVaXlP2g2SrpL0tKS7JPWUNEPSCABJAyQtSpdPkXSzpDskzZd0UdNBJJ0m6TlJM9PjXZZunyLpSkmPABel7xuY7usiaUHTer16cWEPJPju53fljCP35MZfbVfpkKwNRx63lFkP9K90GFUlAjY0NmR6VVrea497AJ+PiH+TdCNwfBvlhwMfBt4GnpX0S6AAnAscCLwJ/AV4oug9OwIHR0RB0mrgJODnwOHAExGxrPgEkiYAEwB22iHvP962FTbCUzO34pe3P8cHejYycdzu7LH/W3z40DWVDs1aMO7fFlEoiPtuG1TpUKpKnh6uyXtN+/mIeDxdng0MbaP8vRGxOiLWA3OBnYGRwP0RsTIiNgDTmr1nWkQ0tRX8BvhCuvxF4OrmJ4iISRExIiJGDNy28lflchs4eAPDRq1lm20L9OgVfHTMGyz4R89Kh2UtOPzYpYz8pxX8dOI+UAVf86uNm0c6R3HDXIHkm8NGNn2uHhnKt+XdO28RsQR4VdIYkmT/5/YGXGs+MvpNFs3rwfq3RGEjPPnQ1uy0p9tLq81HDlnBCacu5j/PHMbb62u/MtFeTb1HsrwqrRa/vy8CPgLMBE7IUP5R4OeS+pE0jxwP/KOV8pOBa4HfFtXAa8pPTt+ZJx/amtUru3LSR/bh5G++Qu9+BS7//g6sXtGVc0/eld32XcePf7eQ3n0LfObLyzjz6D2RYOSYN/jY4W9U+iPUtW9f+DT7f/R1+vTdwDX3PMi1vxrKiV9aTLfujfxoUtLy9+yTfbjsv/aqcKTVpRp6hmRRi0n7YpKp6icAf2qrcES8JOnHJEl+JfAMsLqVt9xK0izyvqaRWvGdK15ocfshR7X8Yxl7/CrGHr+qnCFZO1x0zr7v23bX9O0rEEmOVEktOovcJu2IWATsV7R+cdHu/YuWv5/unwJMKSp/TFGZ6yNiUtqtbzrwh7TMKS2c+gCSG5DPbNEHMLOqEcBG17Rz5T8kHU7SBn4XadJuTtJE4HSSHiRmViPy9ESkkzYQEd/KWO4C4IIyh2NmFeCkbWaWE3nqp+2kbWYGVdEHOwsnbTOzcPOImVluBLCx0b1HzMxyIU9t2vm4tJiZlVmEMr3aIumsdOTRpyT9TlIPSbtIeiQdGfQGSd1LjdNJ28yMjhkwStIOwNeAERGxH9AAfA64ELgkInYHVgGnlRqnk7aZ1b2IDh0wqivQM33CuhewFBgD/D7dPxX4dKmxuk3bzAxR6IAbkelYRhcDi4F1JE9YzwZej4iNabEXgR1KPYdr2mZmtKtNe4CkWUWvCU3HSEcLPRbYBdge2Ar4VEfG6Zq2mdW9do49sjwiRmxm3+Ekk7MsA5B0M3AI0FdS17S2vSPwUqmxuqZtZhZJu3aWVxsWA6Mk9ZIkYCzJLFn3sWl8//HALaWG6qRtZkbH9B6JiEdIbjjOIZlMpQswCTgHOFvSAmBb4NelxunmETOrewGZ+mBnOlbEecB5zTYvJJmicIs5aZuZIQqN+Xgi0knbzIyOq2mXm5O2mdW95Cajk7aZWW7kZcAoJ20zMzJ156sKTtpmVvcC0ejxtM3M8iMnFW0nbTMzfCPSzCxnclLVdtI2M6MGatqSfkkr156I+FpZIjIzq4Ba6D0yq9OiMDOroAiIvPceiYipxeuSekXEW+UPycys8+Wlpt3mpUXSQZLmAs+k6wdIurzskZmZdabI+KqwLN8Hfg58ElgBEBFPAIeVMygzs86VbaqxarhZman3SEQsSSZheFehPOGYmVVIFdSis8iStJdIOhgISd2ArwPzyhuWmVknytHDNVmaR74CnEEy5fvLwPB03cysdoSyvSqszZp2RCwHTuqEWMzMKicnzSNZeo/sKumPkpZJek3SLZJ27YzgzMw6TQ31HrkeuBEYDGwPTAN+V86gzMw6VZCb5pEsSbtXRPw2Ijamr2uBHuUOzMysMyVTjrX9qrTWxh7pny7+WdJE4H9JrkfjgNs7ITYzs85TA7OxzyZJ0k2f5MtF+wL4TrmCMjPrbKqCWnQWrY09sktnBmJmVjFVcpMxi0xPREraD9iHorbsiLimXEGZmXWu6rjJmEWbSVvSecBokqR9O3AU8ADgpG1mtSMnNe0svUdOAMYCr0TEqcABwDZljcrMrLPlpJ92luaRdRHRKGmjpD7Aa8CQMsdlZtZ5gproPdJklqS+wFUkPUrWAA+VNSozs06W+94jTSLiq+nilZLuAPpExJPlDcvMrJPlPWlLOrC1fRExpzwhmZnlV9oyMRnYj+RS8EXgWeAGYCiwCDgxIlaVcvzWato/a2VfAGNKOWE9mf9cP44+Ylylw7B2KKx4ttIhWIV0YPPIL4A7IuIESd2BXsB3gXsj4oL0CfOJwDmlHLy1h2s+UcoBzcxyqQP6aUvahmQ6xlMAIuId4B1Jx5J0nQaYCsygxKSdjznjzczKKYDGjC8YIGlW0WtC0ZF2AZYBV0t6TNJkSVsBgyJiaVrmFWBQqaFmeiLSzKzWtaN5ZHlEjNjMvq7AgcCZEfGIpF+QNIW8KyJCKr0xxjVtMzPoqIdrXgRejIhH0vXfkyTxVyUNBkj/fa3UMLPMXCNJ/0/SD9L1nSSNLPWEZmZVqQOSdkS8QjIZ+l7pprHAXOBWYHy6bTxwS6lhZmkeuZykJWcMcD7wJnAT8NFST2pmVk0UHdp75EzgurTnyELgVJIK8o2STgNeAE4s9eBZkvbHIuJASY8BRMSqNBgzs9rRQY+xR8TjQEtt3mM74vhZkvYGSQ2kXwwkDaTpHqqZWY3Iy2PsWW5EXgpMB7aT9COSYVl/XNaozMw6W62M8hcR10maTVK1F/DpiJhX9sjMzDpLx7Zpl1WWSRB2At4C/li8LSIWlzMwM7NOVStJG/gTmyb47UHyxM+zwL5ljMvMrHPVStKOiGHF6+nof1/dTHEzs1yqmeaR5iJijqSPlSMYM7OKqZWkLensotUuJI9kvly2iMzMOlst3YgEehctbyRp476pPOGYmVVILSTt9KGa3hHxrU6Kx8ysMvKetCV1jYiNkg7pzIDMzDqbqI3mkZkk7dePS7oVmAasbdoZETeXOTYzs84RoJwMzpGlTbsHsIJklL+m/toBOGmbWe2ogZr2dmnPkafYlKyb5OTjmZlllJOs1lrSbgC25r3JuklOPp6ZWTa10Ka9NCLO77RIzMwqqQaSdseMCG5mVu1q5EZkh8yyYGaWC3mvaUfEys4MxMyskmqhTdvMrH44aZuZ5USVTCWWhZO2mdU9kZ+eF07aZmbURu8RM7P64eYRM7MccdI2M8uJGpu5xsys9jlpm5nlh29EmpnliJtHzMzyIkcP13SpdABmZlUhMr4ykNQg6TFJt6Xru0h6RNICSTdI6l5qmE7aZlb3mib2zfLK6OvAvKL1C4FLImJ3YBVwWqmxOmmbmUGH1bQl7Qj8MzA5XRfJHLu/T4tMBT5daphu0zYzC1BjhzVq/xz4NtA7Xd8WeD0iNqbrLwI7lHpw17TNzGhX88gASbOKXhPePYZ0DPBaRMwuV5yuaZuZQXt6jyyPiBGb2XcI8C+SjgZ6AH2AXwB9JXVNa9s7Ai+VGqZr2mZmdMyNyIj4TkTsGBFDgc8Bf4mIk4D7gBPSYuOBW0qN00nbzAw6tMtfC84Bzpa0gKSN+9elHsjNI2ZmZRgwKiJmADPS5YXAyI44rpO2mdU94bFHzMzyJfLxHLuTtpkZHjDKasSAgW/xzW8/Qr9+bxMBd9y+K7dM35Ote7/Nd773MNt9cC2vvbIVP/nhQaxZU/JwClZGW/UpcNbFSxi693oi4L/PHsK82VtVOqzqkqMBo5y0rVWFgpj8P8P5vwX96NlzA5defjdzZg/iiCMX8fhj2zHthg/x2XHz+Ozn5nH15AMqHa614PTzX2LWjN78cMJQunZr5AM9c5KdOlle2rRz2eVP0imSLqt0HPVg1cqe/N+CfgCsW9eNxYv7MGDAOkYd/DL33D0UgHvuHspBB79cwShtc3r1LjBs1FruuL4/ABs3dGHtGw0Vjqo6qTHbq9Jc085IUkNEFCodRyVtN2gtu+3+Os88sy19+61n1cqeAKxa2YO+/dZXODpryQd3eofVKxr45iVL2HXfdcx/shdXnLs9b69z4n6PIDc3IstW05Y0VNI8SVdJelrSXZJ6Shou6WFJT0qaLqlfWn6GpAslzZT0nKRD2zjF9pLukDRf0kVF511TtHyCpCnp8hRJl0p6UNJCSSek27tIulzSM5LulnR70b5FaUxzgInpv03H3qN4vdb16LGB7/3gQSZdMZx1b3Vrtld5+XuvOw0Nwe7D1nHbNdtyxpF7sf6tLoz799cqHVZV6uChWcum3M0jewC/ioh9gdeB44FrgHMiYn/gH8B5ReW7RsRI4BvNtrdkODAOGAaMkzQkQzyDgY8DxwAXpNs+AwwF9gFOBg5q9p4VEXFgRPwIWC1peLr9VODq5ieQNKFpIJl3Cm9lCKn6NTQ08r3zHmTGX3biwQd2BOD1VT3o138dAP36r2P16z0qGaJtxvKl3Vi2tBvPPpbceHzgtm3Yfdi6CkdVpcr7RGSHKXfSfj4iHk+XZwO7AX0j4v5021TgsKLyNxeVHdrGse+NiNURsR6YC+ycIZ4/RERjRMwFBqXbPg5MS7e/QjJGQLEbipYnA6dKaiC5YFzf/AQRMSkiRkTEiO4NvTKEVO2Cb3zzUZYs7sP0m/Z6d+vDD23P4UcsAuDwIxbx8IPbVyg+a82qZd1Y/nJ3dtwtab4afugaFs/3Bba5MkyCUDblbtN+u2i5APTNWL5A27E1P3ZT+eIfa/O/zuL3qI3jN1lbtHwTyTeAvwCzI2JFxmPk1j77LmfsES/w/MJt+OWVdwEw9TfDmPa/e/Odcx/iyKOe57VXe/GTHzb/gmLV4lff34FzLltM127BK4u787OzsnwprTMRuWnT7uwbkauBVZIOjYi/kTRH3N/Ge9rrVUkfAp4FjgPebKP834HxkqYCA4HRtFCDBoiI9ZLuBK5gC6YLypO5Tw/k6CNObHHfd789unODsZIsfLonZx61Z6XDqHrV0DMki0r0HhkPXCmpF7CQpG24I00EbgOWAbOArdsofxMwlqSJZQkwh+TisjnXkVwM7triSM2salRD00cWZUvaEbEI2K9o/eKi3aNaKD+6aHk5rbRpR8QUYErR+jFFy79n01xsxe85pdn61um/jZK+FRFrJG0LzCS5QUo6Jm5zHweurvfuf2Y1JYCOm26srNxPO3GbpL5Ad+C/0huS7yNpOsnN1DGdGZyZdYJ85OzqTtqSPkky9Xyx5yPiuI48T3Etv41yHXpeM6sedd880hEi4k7gzkrHYWZ1wL1HzMxyItx7xMwsN5KHa1zTNjPLD9e0zczywzVtM7O8qJLBoLJw0jYzI5AfrjEzyxE3j5iZ5YS7/JmZ5Yxr2mZmOZKPnO2kbWYG7vJnZpYfARSctM3MckGEa9pmZrmSk6Rd7tnYzczyoWly37ZerZA0RNJ9kuZKelrS19Pt/SXdLWl++m+/UsN00jYzC5IBo7K8WrcR+GZE7EMyreIZkvYhmbv23ojYA7g3XS+Jk7aZGUnvkSyv1kTE0oiYky6/CcwDdgCOBaamxaYCny41Trdpm5kR0Jj5kcgBkmYVrU+KiEnNC0kaCnwYeAQYFBFL012vAINKjdRJ28wsaM+NyOURMaK1ApK2Bm4CvhERb0jadKqIkEqfkdLNI2Zm0FFt2kjqRpKwr4uIm9PNr0oanO4fDLxWaphO2mZmdEybtpIq9a+BeRHx30W7bgXGp8vjgVtKjdPNI2Zm0FH9tA8BTgb+IenxdNt3gQuAGyWdBrwAnFjqCZy0zcwioLDlY7NGxAMk8wS3ZOwWnwAnbTOzRE6eiHTSNjMDJ20zs9wIwHNEmpnlRUDkY74xJ20zM3DziJlZbgQd0nukMzhpm5mBa9pmZvnR9ljZ1cJJ28wsaM8ofxXlpG1mBq5pm5nlipO2mVlORBCFQqWjyMRJ28wM/ESkmVmuuHnEzCwnol1zRFaUk7aZGbimbWaWH74RaWaWHx6a1cwsZzw0q5lZPgQQrmmbmeVEeBIEM7NcyUtNW5GTbi55JGkZ8EKl4yiTAcDySgdh7VKrv7OdI2LglhxA0h0kP58slkfEp7bkfFvCSdtKImlWRIyodByWnX9ntaFLpQMwM7PsnLTNzHLESdtKNanSAVi7+XdWA9ymbWaWI65pm5nliJO2mVmOOGnXIUlDJT1V6TjMrP2ctK3sJPnJ204k6RRJl1U6DisPJ+361SDpKklPS7pLUk9JMySNAJA0QNKidPkUSTdLukPSfEkXNR1E0mmSnpM0Mz3eZen2KZKulPQIcFH6voHpvi6SFjStW/5Jaqh0DPXCSbt+7QH8KiL2BV4Hjm+j/HBgHDAMGCdpiKTtgXOBUcAhwN7N3rMjcHBEnA1cC5yUbj8ceCIilnXIJ8mhtIlqXgsXzuGSHpb0pKTpkvql5WdIujC9OD4n6dA2TrH9Zi6ya4qWT5A0JV2eIulSSQ9KWijphHR7F0mXS3pG0t2Sbi/atyiNaQ4wMf236dh7FK9bx3HSrl/PR8Tj6fJsYGgb5e+NiNURsR6YC+wMjATuj4iVEbEBmNbsPdMiomk6kN8AX0iXvwhcvaUfoAa0dOG8BjgnIvYH/gGcV1S+a0SMBL7RbHtL3neRzRDPYODjwDHABem2z5D8bewDnAwc1Ow9KyLiwIj4EbBa0vB0+6n4d1wWTtr16+2i5QLJiI8b2fQ30SND+basbVqIiCXAq5LGkCT7P7c34BrU/MK5G9A3Iu5Pt00FDisqf3NR2aFtHLuli2xb/hARjRExFxiUbvs4ycW3MSJeAe5r9p4bipYnA6emTSXjgOsznNPayUnbii0CPpIun5Ch/KPAP0nql95sbKuJZTJJM0lxDbyeNb8Q9s1YPstFc3MX2eKn6Vq7MKuN4zdZW7R8E3AUSU19dkSsyHgMawcnbSt2MXC6pMfIMExlRLwE/BiYCfydJOmvbuUttwJb46/Nm7MaWFXUXn0ycH8r5UvxqqQPSeoCHJeh/N+B49O27UHA6M0VTGv1dwJX4N9x2bgrVh2KiEXAfkXrFxft3r9o+fvp/inAlKLyxxSVuT4iJqU17enAH9Iyp7Rw6gNIbkA+s0UfoLaNB66U1AtYSNI23JEmArcBy4BZJBfR1twEjCVpYlkCzKH1C/N1JBeDu7Y4UmuRxx6xLSLpYpLeID1I/qN+PVr4o5I0ETgdOCkiHujcKG1LSNo6ItZI2pbkW9Uhaft2S2W/BWwTEed2apB1xEnbzFolaQZJe3t34KL0m1dL5aaT3EwdExG1OENOVXDSNsspSZ8ELmy2+fmIyNJWbTnlpG1mliPuPWJmliNO2mZmOeKkbRUlqSDpcUlPSZqWdnUr9VhTisbFmCxpn1bKjpZ0cAnnWCTpfX3YN7e9WZk1re1vofx/pL0xzN7lpG2Vti4ihkfEfsA7wFeKd5Y6rGtEfCl9HHtzRgPtTtpmleakbdXkb8DuaS34b5JuBeZKapD0U0mPpqPffRlAicskPSvpHmC7pgM1G2b2U5LmSHpC0r2ShpJcHM5Ka/mHShoo6ab0HI9KOiR977bpCHxPS5pMhse7Jf1B0uz0PROa7bsk3X5v0VC1u6Uj8s1OP3fz0RLN3uUnIq0qpDXqo4A70k0HAvtFxPNp4lsdER+V9AHg75LuAj4M7EUyAt0gkqf2ftPsuAOBq4DD0mP1j4iVkq4E1jQ9DSrpeuCSiHhA0k4kj2N/iGQ0vQci4nxJ/wycluHjfDE9R0/gUUk3peNwbAXMioizJP0gPfa/k8yS/pWImC/pY8DlwJgSfoxWB5y0rdJ6Smoa6e5vwK9Jmi1mRsTz6fYjgf2b2quBbUiGNT0M+F06+NTLkv7SwvFHAX9tOlZErNxMHIcD+0jvVqT7SNo6Pcdn0vf+SdKqDJ/pa5Ka+koPSWNdATSyaVS8a4Gb03McDEwrOvcHMpzD6pSTtlXauogYXrwhTV7Fo8cJODMi7mxW7ugOjKMLMCod9Kh5LJlJGk1yATgoIt5KnyZsPppek0jP+3rzn4HZ5rhN2/LgTpLRB7sBSNpT0lbAX0kG+G+QNBj4RAvvfRg4TNIu6Xv7p9vfBHoXlbsLOLNppWgw/78C/5puOwro10as2wCr0oS9N0lNv0kXNg15+68kzS5vAM9L+mx6Dkk6oI1zWB1z0rY8mEzSXj1HySzy/0PyLXE6MD/ddw3wUPM3plOaTSBpiniCTc0TfwSOa7oRCXwNGJHe6JzLpl4s/0mS9J8maSZZ3EasdwBdJc0jmf3l4aJ9a4GR6WcYA5yfbj8JOC2N72ng2Aw/E6tTfozdzCxHXNM2M8sRJ20zsxxx0jYzyxEnbTOzHHHSNjPLESdtM7MccdI2M8uR/w9QWDXdHcwwpwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=class_names)\n",
        "disp.plot()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "xsWVsk_w4KEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd782f7e-e32e-40f7-d07a-6c6b44cf19f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Hungry       0.85      0.91      0.88       128\n",
            "  Non_hungry       0.33      0.23      0.27        26\n",
            "\n",
            "    accuracy                           0.79       154\n",
            "   macro avg       0.59      0.57      0.58       154\n",
            "weighted avg       0.77      0.79      0.78       154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred,target_names=[\"Hungry\",\"Non_hungry\"]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MICls6lpDG0E"
      },
      "execution_count": 213,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "23bf0724a01b6ea9814e66f76182ea78c0ee849a72ca257c0e116bf83bb4960a"
      }
    },
    "colab": {
      "name": "train_evaluate.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}