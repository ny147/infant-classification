{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ny147/infant-classification/blob/pete/train_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cpHscK9W4KEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05934847-68b4-4519-826c-352a0f06d901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: focal_loss in /usr/local/lib/python3.7/dist-packages (0.0.7)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal_loss) (2.8.2+zzzcolab20220629235552)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.3.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (14.0.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.21.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.14.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (57.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (4.1.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.47.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal_loss) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2->focal_loss) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.3.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa, librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import shutil\n",
        "!pip install focal_loss\n",
        "from focal_loss import BinaryFocalLoss\n",
        "#import ftransc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Colab"
      ],
      "metadata": {
        "id": "kvNMNbwc5MmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/Infant_cry\"\n",
        "train_directory = path + '/mel_spectrogram/train_oneclass/hungry_one'\n",
        "test_directory = path + '/mel_spectrogram/test_oneclass/hungry_one'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1P1SA9q4LFI",
        "outputId": "229f96af-31a3-4e43-f6e5-3e89e24b5507"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local "
      ],
      "metadata": {
        "id": "k1BjHEUS5uZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_directory = path + '/data_matlab/train/'\n",
        "# test_directory = path + '/data_matlab/test/'"
      ],
      "metadata": {
        "id": "R3-uUE3m5rWW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FDsbZ0NX4KEg",
        "outputId": "f36a6e60-ba75-4bab-eeb6-1485123ec30d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 303 files belonging to 2 classes.\n",
            "Found 154 files belonging to 2 classes.\n",
            "['hungry', 'non_hungry']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_directory, labels='inferred', label_mode='int', image_size=(256, 256), seed=321,\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_directory, labels='inferred', label_mode='int', image_size=(256, 256),\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hMp3ZErr4KEi"
      },
      "outputs": [],
      "source": [
        "## create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WRnYz0BQ4KEi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SGjcs6ok4KEj"
      },
      "outputs": [],
      "source": [
        "x_train=[]\n",
        "y_train=[]\n",
        "for images, labels in train_ds.unbatch().take(-1):\n",
        "    x_train.append(images.numpy())\n",
        "    y_train.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "52Syhv1s4KEj"
      },
      "outputs": [],
      "source": [
        "x_test=[]\n",
        "y_test=[]\n",
        "for images, labels in test_ds.unbatch().take(-1):\n",
        "    x_test.append(images.numpy())\n",
        "    y_test.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pTeqzMX54KEk"
      },
      "outputs": [],
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KuLx5bbv4KEk"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "def create_weight(n_sample,n_class,n_class_sample):\n",
        "    weight = n_sample/(n_class*n_class_sample)\n",
        "    return weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_PLcfLrI4KEl"
      },
      "outputs": [],
      "source": [
        "class_weights = {0:0, 1:0}\n",
        "class_count = np.array([254,49])\n",
        "for i in range(num_classes):\n",
        "    class_weights[i]=create_weight(306,num_classes,class_count[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "CXXvqKtk4KEl",
        "outputId": "0d19f749-cc4b-4f24-8223-71ae8b27637e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_4 (Rescaling)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " tf.cast_2 (TFOpLambda)      (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " xception (Functional)       (None, 8, 8, 2048)        20861480  \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            " activation_205 (Activation)  (None, 1)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,863,529\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.applications.Xception(\n",
        "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(img_height, img_width, 3),\n",
        "    include_top=False,\n",
        ")  # Do not include the ImageNet classifier at the top.\n",
        "\n",
        "# base_model = tf.keras.applications.ResNet50V2(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_tensor=None,\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     pooling=None,\n",
        "#     # classes=1000,\n",
        "#     classifier_activation=\"softmax\",\n",
        "# )\n",
        "# base_model = tf.keras.applications.InceptionResNetV2(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     pooling=None,\n",
        "#     classifier_activation=\"softmax\"\n",
        "# )\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create new model on top\n",
        "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "#x = data_augmentation(inputs)  # Apply random data augmentation\n",
        "\n",
        "# Pre-trained Xception weights requires that input be scaled\n",
        "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
        "# outputs: `(inputs * scale) + offset`\n",
        "scale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
        "x = scale_layer(inputs)\n",
        "\n",
        "x = tf.cast(x,tf.float32)\n",
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "# x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(1)(x)\n",
        "outputs = tf.keras.layers.Activation('sigmoid')(outputs)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5mS95CLp4KEm",
        "outputId": "7995a064-0069-4a2c-ef71-cbc5269a12a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_5 (Rescaling)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d_217 (Conv2D)         (None, 256, 256, 256)     7168      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 128, 128, 256)    0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " conv2d_218 (Conv2D)         (None, 128, 128, 128)     295040    \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 64, 64, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_219 (Conv2D)         (None, 64, 64, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 32, 32, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 65536)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                4194368   \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,570,433\n",
            "Trainable params: 4,570,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "            tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ENIr5nXA4KEn"
      },
      "outputs": [],
      "source": [
        "#resnet \n",
        "#inception v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "B-6CMHob4KEo"
      },
      "outputs": [],
      "source": [
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 20)\n",
        "earlystop_callback2 = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy',patience = 20)\n",
        "# loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "loss_fn = BinaryFocalLoss(gamma=2)\n",
        "optimizer = tf.keras.optimizers.Adam()# modify weight in Adam\n",
        "metrics = ['accuracy']\n",
        "model.compile (optimizer = optimizer,loss =  loss_fn,metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2I_oiDJ94KEo",
        "outputId": "6bfbf7cc-f46b-42b3-e6a0-d8c7a0e5f6a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 4s 512ms/step - loss: 1.1258 - accuracy: 0.4057 - val_loss: 0.2808 - val_accuracy: 0.1648\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 3s 391ms/step - loss: 0.1964 - accuracy: 0.5755 - val_loss: 0.1970 - val_accuracy: 0.1648\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 3s 371ms/step - loss: 0.1789 - accuracy: 0.1604 - val_loss: 0.1716 - val_accuracy: 0.8352\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.1744 - accuracy: 0.5943 - val_loss: 0.1714 - val_accuracy: 0.8352\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 2s 361ms/step - loss: 0.1742 - accuracy: 0.8396 - val_loss: 0.1713 - val_accuracy: 0.8352\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 2s 361ms/step - loss: 0.1742 - accuracy: 0.8396 - val_loss: 0.1707 - val_accuracy: 0.8352\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 2s 361ms/step - loss: 0.1742 - accuracy: 0.8160 - val_loss: 0.1703 - val_accuracy: 0.8352\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 2s 361ms/step - loss: 0.1735 - accuracy: 0.8396 - val_loss: 0.1685 - val_accuracy: 0.8242\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.1724 - accuracy: 0.8208 - val_loss: 0.1669 - val_accuracy: 0.7802\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.1711 - accuracy: 0.6651 - val_loss: 0.1661 - val_accuracy: 0.7143\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 2s 361ms/step - loss: 0.1665 - accuracy: 0.5425 - val_loss: 0.1268 - val_accuracy: 0.8022\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.1695 - accuracy: 0.6415 - val_loss: 0.1627 - val_accuracy: 0.5714\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.1630 - accuracy: 0.5991 - val_loss: 0.1531 - val_accuracy: 0.6593\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 2s 361ms/step - loss: 0.1570 - accuracy: 0.7311 - val_loss: 0.1431 - val_accuracy: 0.6923\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.1472 - accuracy: 0.5708 - val_loss: 0.1328 - val_accuracy: 0.6813\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 3s 363ms/step - loss: 0.1464 - accuracy: 0.7925 - val_loss: 0.1369 - val_accuracy: 0.6374\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 2s 363ms/step - loss: 0.1382 - accuracy: 0.6887 - val_loss: 0.1400 - val_accuracy: 0.6484\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 3s 363ms/step - loss: 0.1172 - accuracy: 0.8019 - val_loss: 0.1790 - val_accuracy: 0.5934\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 3s 363ms/step - loss: 0.1085 - accuracy: 0.7642 - val_loss: 0.1616 - val_accuracy: 0.6264\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 3s 363ms/step - loss: 0.0985 - accuracy: 0.8302 - val_loss: 0.1662 - val_accuracy: 0.6154\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 3s 363ms/step - loss: 0.0905 - accuracy: 0.7594 - val_loss: 0.1874 - val_accuracy: 0.6703\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.0785 - accuracy: 0.8491 - val_loss: 0.1690 - val_accuracy: 0.6264\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.0712 - accuracy: 0.8396 - val_loss: 0.1951 - val_accuracy: 0.7363\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 3s 363ms/step - loss: 0.0615 - accuracy: 0.8915 - val_loss: 0.2929 - val_accuracy: 0.7143\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.0484 - accuracy: 0.8962 - val_loss: 0.2402 - val_accuracy: 0.6813\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.0351 - accuracy: 0.9575 - val_loss: 0.2459 - val_accuracy: 0.6813\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.0288 - accuracy: 0.9481 - val_loss: 0.3157 - val_accuracy: 0.7802\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.0202 - accuracy: 0.9811 - val_loss: 0.3358 - val_accuracy: 0.6813\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 3s 363ms/step - loss: 0.0267 - accuracy: 0.9292 - val_loss: 0.3864 - val_accuracy: 0.7802\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.0209 - accuracy: 0.9717 - val_loss: 0.3310 - val_accuracy: 0.7033\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.0196 - accuracy: 0.9764 - val_loss: 0.3328 - val_accuracy: 0.8242\n"
          ]
        }
      ],
      "source": [
        "# Set the epocks\n",
        "# ทำ stop + validation\n",
        "epochs = 50\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights,callbacks = [earlystop_callback,earlystop_callback2])\n",
        "# history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights)\n",
        "#history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "G9oorLuK4KEo",
        "outputId": "6d32a134-3b0c-45bf-d43f-c1d2945ec817",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_5 (Rescaling)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d_217 (Conv2D)         (None, 256, 256, 256)     7168      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 128, 128, 256)    0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " conv2d_218 (Conv2D)         (None, 128, 128, 128)     295040    \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 64, 64, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_219 (Conv2D)         (None, 64, 64, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 32, 32, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 65536)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                4194368   \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,570,433\n",
            "Trainable params: 4,570,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "7/7 [==============================] - 3s 409ms/step - loss: 0.0108 - binary_accuracy: 1.0000 - val_loss: 0.3372 - val_binary_accuracy: 0.8242\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 3s 372ms/step - loss: 0.0116 - binary_accuracy: 0.9953 - val_loss: 0.3368 - val_binary_accuracy: 0.8022\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0111 - binary_accuracy: 0.9906 - val_loss: 0.3379 - val_binary_accuracy: 0.8022\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.0073 - binary_accuracy: 0.9953 - val_loss: 0.3389 - val_binary_accuracy: 0.8022\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.0073 - binary_accuracy: 0.9953 - val_loss: 0.3406 - val_binary_accuracy: 0.8022\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.0071 - binary_accuracy: 0.9953 - val_loss: 0.3427 - val_binary_accuracy: 0.8022\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.0077 - binary_accuracy: 0.9953 - val_loss: 0.3446 - val_binary_accuracy: 0.8022\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0069 - binary_accuracy: 0.9953 - val_loss: 0.3467 - val_binary_accuracy: 0.8132\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.0070 - binary_accuracy: 0.9953 - val_loss: 0.3481 - val_binary_accuracy: 0.8022\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 0.0059 - binary_accuracy: 1.0000 - val_loss: 0.3500 - val_binary_accuracy: 0.8022\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.0058 - binary_accuracy: 0.9953 - val_loss: 0.3519 - val_binary_accuracy: 0.8022\n"
          ]
        }
      ],
      "source": [
        "earlystop_callback2 = tf.keras.callbacks.EarlyStopping(monitor = 'binary_accuracy',patience = 10,min_delta=0)\n",
        "base_model.trainable = True\n",
        "model.summary()\n",
        "# loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss = BinaryFocalLoss(gamma=2),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,callbacks = [earlystop_callback,earlystop_callback2],class_weight = class_weights)\n",
        "# history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cQ7QKhSO4KEp"
      },
      "outputs": [],
      "source": [
        "def binary_transform(pred):\n",
        "    if pred > 0.5:\n",
        "        predicted = 1\n",
        "    else:\n",
        "        predicted = 0\n",
        "    return predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NTHyhXUb4KEp"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(x_test)\n",
        "\n",
        "vfunc = np.vectorize(binary_transform)\n",
        "y_pred = vfunc(pred)\n",
        "actual = x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "a3MuHsl24KEp",
        "outputId": "47d5b7ea-6abb-4b4d-eb51-848225c92cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=class_names)\n",
        "disp.plot()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "xsWVsk_w4KEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "551f8e3d-69a5-4ef6-f7df-119755e003e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Hungry       0.85      0.88      0.87       128\n",
            "  Non_hungry       0.29      0.23      0.26        26\n",
            "\n",
            "    accuracy                           0.77       154\n",
            "   macro avg       0.57      0.56      0.56       154\n",
            "weighted avg       0.75      0.77      0.76       154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred,target_names=[\"Hungry\",\"Non_hungry\"]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MICls6lpDG0E"
      },
      "execution_count": 24,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "23bf0724a01b6ea9814e66f76182ea78c0ee849a72ca257c0e116bf83bb4960a"
      }
    },
    "colab": {
      "name": "train_evaluate.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}