{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ny147/infant-classification/blob/pete/train_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cpHscK9W4KEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344864e7-0584-4644-9d65-1e0105cd3634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting focal_loss\n",
            "  Downloading focal_loss-0.0.7-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal_loss) (2.8.2+zzzcolab20220629235552)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (4.1.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.47.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (14.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.26.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.5.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal_loss) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2->focal_loss) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.2.0)\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.7\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa, librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import shutil\n",
        "!pip install focal_loss\n",
        "from focal_loss import BinaryFocalLoss\n",
        "#import ftransc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Colab"
      ],
      "metadata": {
        "id": "kvNMNbwc5MmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/Infant_cry\"\n",
        "train_directory = path + '/mel_spectrogram/train_oneclass/hungry_one'\n",
        "test_directory = path + '/mel_spectrogram/test_oneclass/hungry_one'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1P1SA9q4LFI",
        "outputId": "5c5b9a19-f4dd-468f-fe62-f1a0d9ca85e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local "
      ],
      "metadata": {
        "id": "k1BjHEUS5uZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_directory = path + '/data_matlab/train/'\n",
        "# test_directory = path + '/data_matlab/test/'"
      ],
      "metadata": {
        "id": "R3-uUE3m5rWW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FDsbZ0NX4KEg",
        "outputId": "de8a68b5-8f2a-48c0-d3f5-95664604726c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 303 files belonging to 2 classes.\n",
            "Found 154 files belonging to 2 classes.\n",
            "['hungry', 'non_hungry']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_directory, labels='inferred', label_mode='int', image_size=(256, 256), seed=321,\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_directory, labels='inferred', label_mode='int', image_size=(256, 256),\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hMp3ZErr4KEi"
      },
      "outputs": [],
      "source": [
        "## create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WRnYz0BQ4KEi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SGjcs6ok4KEj"
      },
      "outputs": [],
      "source": [
        "x_train=[]\n",
        "y_train=[]\n",
        "for images, labels in train_ds.unbatch().take(-1):\n",
        "    x_train.append(images.numpy())\n",
        "    y_train.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "52Syhv1s4KEj"
      },
      "outputs": [],
      "source": [
        "x_test=[]\n",
        "y_test=[]\n",
        "for images, labels in test_ds.unbatch().take(-1):\n",
        "    x_test.append(images.numpy())\n",
        "    y_test.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pTeqzMX54KEk"
      },
      "outputs": [],
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KuLx5bbv4KEk"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "def create_weight(n_sample,n_class,n_class_sample):\n",
        "    weight = n_sample/(n_class*n_class_sample)\n",
        "    return weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "_PLcfLrI4KEl"
      },
      "outputs": [],
      "source": [
        "class_weights = {0:0, 1:0}\n",
        "class_count = np.array([254,49])\n",
        "for i in range(num_classes):\n",
        "    class_weights[i]=create_weight(306,num_classes,class_count[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "CXXvqKtk4KEl",
        "outputId": "e7f3f211-def8-4932-a49c-0e8ed24d0476",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_26 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_24 (Rescaling)    (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " tf.cast_12 (TFOpLambda)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " inception_resnet_v2 (Functi  (None, 6, 6, 1536)       54336736  \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " global_average_pooling2d_12  (None, 1536)             0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 1536)              0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 1)                 1537      \n",
            "                                                                 \n",
            " activation_2042 (Activation  (None, 1)                0         \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,338,273\n",
            "Trainable params: 1,537\n",
            "Non-trainable params: 54,336,736\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# base_model = tf.keras.applications.Xception(\n",
        "#     weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     include_top=False,\n",
        "# )  # Do not include the ImageNet classifier at the top.\n",
        "\n",
        "# base_model = tf.keras.applications.ResNet50V2(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_tensor=None,\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     pooling=None,\n",
        "#     # classes=1000,\n",
        "#     classifier_activation=\"softmax\",\n",
        "# )\n",
        "base_model = tf.keras.applications.InceptionResNetV2(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(img_height, img_width, 3),\n",
        "    pooling=None,\n",
        "    classifier_activation=\"softmax\"\n",
        ")\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create new model on top\n",
        "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "#x = data_augmentation(inputs)  # Apply random data augmentation\n",
        "\n",
        "# Pre-trained Xception weights requires that input be scaled\n",
        "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
        "# outputs: `(inputs * scale) + offset`\n",
        "scale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
        "x = scale_layer(inputs)\n",
        "\n",
        "x = tf.cast(x,tf.float32)\n",
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "# x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(1)(x)\n",
        "outputs = tf.keras.layers.Activation('sigmoid')(outputs)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "5mS95CLp4KEm",
        "outputId": "e84a30c4-c39a-47c4-e9f0-4ee6bdfee38c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_25 (Rescaling)    (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d_2074 (Conv2D)        (None, 256, 256, 256)     7168      \n",
            "                                                                 \n",
            " max_pooling2d_79 (MaxPoolin  (None, 128, 128, 256)    0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " conv2d_2075 (Conv2D)        (None, 128, 128, 128)     295040    \n",
            "                                                                 \n",
            " max_pooling2d_80 (MaxPoolin  (None, 64, 64, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2076 (Conv2D)        (None, 64, 64, 32)        36896     \n",
            "                                                                 \n",
            " max_pooling2d_81 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 64)                2097216   \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,436,385\n",
            "Trainable params: 2,436,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "            tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "ENIr5nXA4KEn"
      },
      "outputs": [],
      "source": [
        "#resnet \n",
        "#inception v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "B-6CMHob4KEo"
      },
      "outputs": [],
      "source": [
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 19,min_delta = 0)\n",
        "earlystop_callback2 = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy',patience = 19,min_delta = 0)\n",
        "# loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "loss_fn = BinaryFocalLoss(gamma=2)\n",
        "optimizer = tf.keras.optimizers.Adam()# modify weight in Adam\n",
        "metrics = ['accuracy']\n",
        "model.compile (optimizer = optimizer,loss =  loss_fn,metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "2I_oiDJ94KEo",
        "outputId": "4a8f77b8-8d06-485e-f940-920588c5cc6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 3s 398ms/step - loss: 0.4143 - accuracy: 0.3821 - val_loss: 0.1800 - val_accuracy: 0.1648\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.1753 - accuracy: 0.4575 - val_loss: 0.1730 - val_accuracy: 0.6593\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 3s 371ms/step - loss: 0.1797 - accuracy: 0.6887 - val_loss: 0.1737 - val_accuracy: 0.2637\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.1738 - accuracy: 0.7594 - val_loss: 0.1693 - val_accuracy: 0.5934\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.1709 - accuracy: 0.6038 - val_loss: 0.1539 - val_accuracy: 0.7143\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 3s 363ms/step - loss: 0.1657 - accuracy: 0.7075 - val_loss: 0.1818 - val_accuracy: 0.2857\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.1722 - accuracy: 0.3491 - val_loss: 0.1701 - val_accuracy: 0.4286\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 2s 363ms/step - loss: 0.1641 - accuracy: 0.5472 - val_loss: 0.1401 - val_accuracy: 0.6593\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.1514 - accuracy: 0.6085 - val_loss: 0.1713 - val_accuracy: 0.5385\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 2s 363ms/step - loss: 0.1507 - accuracy: 0.5849 - val_loss: 0.1583 - val_accuracy: 0.5824\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.1377 - accuracy: 0.5755 - val_loss: 0.1535 - val_accuracy: 0.6044\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.1290 - accuracy: 0.7264 - val_loss: 0.1662 - val_accuracy: 0.6264\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.1174 - accuracy: 0.6557 - val_loss: 0.1748 - val_accuracy: 0.6484\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.1131 - accuracy: 0.6840 - val_loss: 0.1956 - val_accuracy: 0.6154\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.1030 - accuracy: 0.7689 - val_loss: 0.2048 - val_accuracy: 0.6154\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.1258 - accuracy: 0.5660 - val_loss: 0.1476 - val_accuracy: 0.5934\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.1237 - accuracy: 0.8019 - val_loss: 0.1619 - val_accuracy: 0.6813\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.1013 - accuracy: 0.7689 - val_loss: 0.2523 - val_accuracy: 0.6593\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0902 - accuracy: 0.7547 - val_loss: 0.2290 - val_accuracy: 0.6703\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.0838 - accuracy: 0.7925 - val_loss: 0.2329 - val_accuracy: 0.6923\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.0686 - accuracy: 0.8585 - val_loss: 0.2916 - val_accuracy: 0.7253\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.0695 - accuracy: 0.8632 - val_loss: 0.3234 - val_accuracy: 0.7033\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 3s 363ms/step - loss: 0.0778 - accuracy: 0.7972 - val_loss: 0.2291 - val_accuracy: 0.6923\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.0781 - accuracy: 0.8868 - val_loss: 0.2870 - val_accuracy: 0.7143\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.0672 - accuracy: 0.8726 - val_loss: 0.4515 - val_accuracy: 0.6923\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.0645 - accuracy: 0.8302 - val_loss: 0.3374 - val_accuracy: 0.7253\n"
          ]
        }
      ],
      "source": [
        "# Set the epocks\n",
        "# ทำ stop + validation\n",
        "epochs = 50\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights,callbacks = [earlystop_callback,earlystop_callback2])\n",
        "# history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights)\n",
        "#history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "G9oorLuK4KEo",
        "outputId": "241eecf4-966a-4e59-8fda-9cbc207a90e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_25 (Rescaling)    (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d_2074 (Conv2D)        (None, 256, 256, 256)     7168      \n",
            "                                                                 \n",
            " max_pooling2d_79 (MaxPoolin  (None, 128, 128, 256)    0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " conv2d_2075 (Conv2D)        (None, 128, 128, 128)     295040    \n",
            "                                                                 \n",
            " max_pooling2d_80 (MaxPoolin  (None, 64, 64, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2076 (Conv2D)        (None, 64, 64, 32)        36896     \n",
            "                                                                 \n",
            " max_pooling2d_81 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 64)                2097216   \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,436,385\n",
            "Trainable params: 2,436,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "7/7 [==============================] - 3s 393ms/step - loss: 0.0542 - binary_accuracy: 0.9245 - val_loss: 0.3418 - val_binary_accuracy: 0.7253\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 2s 360ms/step - loss: 0.0530 - binary_accuracy: 0.8915 - val_loss: 0.3478 - val_binary_accuracy: 0.7253\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 2s 360ms/step - loss: 0.0537 - binary_accuracy: 0.8915 - val_loss: 0.3554 - val_binary_accuracy: 0.7253\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 2s 361ms/step - loss: 0.0567 - binary_accuracy: 0.8962 - val_loss: 0.3617 - val_binary_accuracy: 0.7253\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.0505 - binary_accuracy: 0.9104 - val_loss: 0.3677 - val_binary_accuracy: 0.7253\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 2s 361ms/step - loss: 0.0518 - binary_accuracy: 0.9057 - val_loss: 0.3736 - val_binary_accuracy: 0.7253\n"
          ]
        }
      ],
      "source": [
        "earlystop_callback2 = tf.keras.callbacks.EarlyStopping(monitor = 'binary_accuracy',patience = 10,min_delta=0)\n",
        "base_model.trainable = True\n",
        "model.summary()\n",
        "# loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss = BinaryFocalLoss(gamma=2),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,callbacks = [earlystop_callback,earlystop_callback2],class_weight = class_weights)\n",
        "# history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "cQ7QKhSO4KEp"
      },
      "outputs": [],
      "source": [
        "def binary_transform(pred):\n",
        "    if pred > 0.5:\n",
        "        predicted = 1\n",
        "    else:\n",
        "        predicted = 0\n",
        "    return predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "NTHyhXUb4KEp"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(x_test)\n",
        "\n",
        "vfunc = np.vectorize(binary_transform)\n",
        "y_pred = vfunc(pred)\n",
        "actual = x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "a3MuHsl24KEp",
        "outputId": "6b32e856-1b22-45a3-91f8-2d03b279a466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {},
          "execution_count": 145
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=class_names)\n",
        "disp.plot()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "xsWVsk_w4KEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "462064b6-6fcd-4c38-b12b-749b4a3caed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Hungry       0.84      0.79      0.81       128\n",
            "  Non_hungry       0.21      0.27      0.23        26\n",
            "\n",
            "    accuracy                           0.70       154\n",
            "   macro avg       0.52      0.53      0.52       154\n",
            "weighted avg       0.73      0.70      0.72       154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred,target_names=[\"Hungry\",\"Non_hungry\"]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MICls6lpDG0E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "23bf0724a01b6ea9814e66f76182ea78c0ee849a72ca257c0e116bf83bb4960a"
      }
    },
    "colab": {
      "name": "train_evaluate.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}