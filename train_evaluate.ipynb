{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 44,
=======
   "execution_count": 1,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import shutil\n",
    "#import ftransc"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 45,
=======
   "execution_count": 4,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 306 files belonging to 2 classes.\n",
      "Found 151 files belonging to 2 classes.\n",
      "['hungry', 'non_hungry']\n"
     ]
    }
   ],
   "source": [
    "# typeimg='mel_spectrogram'\n",
    "train_directory = './data_matlab/train/'\n",
    "test_directory = './data_matlab/test/'\n",
    "\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_directory, labels='inferred', label_mode='int', image_size=(256, 256), seed=321,\n",
    "    validation_split=None, subset=None)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_directory, labels='inferred', label_mode='int', image_size=(256, 256),\n",
    "    validation_split=None, subset=None)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 46,
=======
   "execution_count": 5,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 47,
=======
   "execution_count": 6,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 48,
=======
   "execution_count": 7,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "for images, labels in train_ds.unbatch().take(-1):\n",
    "    x_train.append(images.numpy())\n",
    "    y_train.append(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 49,
=======
   "execution_count": 8,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[]\n",
    "y_test=[]\n",
    "for images, labels in test_ds.unbatch().take(-1):\n",
    "    x_test.append(images.numpy())\n",
    "    y_test.append(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 50,
=======
   "execution_count": 9,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 51,
=======
   "execution_count": 10,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "def create_weight(n_sample,n_class,n_class_sample):\n",
    "    weight = n_sample/(n_class*n_class_sample)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 52,
=======
   "execution_count": 11,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0:0, 1:0}\n",
    "class_count = np.array([254,49])\n",
    "for i in range(num_classes):\n",
    "    class_weights[i]=create_weight(303,num_classes,class_count[i])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 53,
=======
   "execution_count": 12,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_32 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_17 (Rescaling)    (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " tf.cast_10 (TFOpLambda)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " xception (Functional)       (None, 8, 8, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_13  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 2049      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.Xception(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
    "#x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "\n",
    "# Pre-trained Xception weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "scale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
    "x = scale_layer(inputs)\n",
    "\n",
    "x = tf.cast(x,tf.float32)\n",
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "# x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "outputs = tf.keras.layers.Activation('sigmoid')(outputs)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_3 (Rescaling)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 256, 256, 256)     7168      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 128, 128, 256)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128, 128, 256)     0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 128, 128, 128)     295040    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 64, 64, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 64, 64, 16)        18448     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 32, 32, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                1048640   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,369,361\n",
      "Trainable params: 1,369,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "            tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2,2)),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \n",
    "            tf.keras.layers.MaxPooling2D((2,2)),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2,2)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 54,
=======
   "execution_count": 13,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet \n",
    "#inception v3"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 55,
=======
   "execution_count": 14,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()# modify weight in Adam\n",
    "metrics = ['accuracy']\n",
    "model.compile (optimizer = optimizer,loss =  loss_fn,metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 57,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Epoch 1/10\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.8348 - accuracy: 0.8396 - val_loss: 0.5557 - val_accuracy: 0.8242\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 17s 3s/step - loss: 0.6681 - accuracy: 0.6698 - val_loss: 0.7740 - val_accuracy: 0.2308\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 15s 2s/step - loss: 0.6714 - accuracy: 0.2500 - val_loss: 0.8152 - val_accuracy: 0.1978\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 18s 3s/step - loss: 0.6579 - accuracy: 0.3585 - val_loss: 0.6896 - val_accuracy: 0.5385\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 16s 2s/step - loss: 0.6557 - accuracy: 0.6981 - val_loss: 0.5987 - val_accuracy: 0.8132\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 19s 3s/step - loss: 0.6550 - accuracy: 0.7311 - val_loss: 0.6386 - val_accuracy: 0.7473\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 17s 3s/step - loss: 0.6348 - accuracy: 0.7217 - val_loss: 0.6455 - val_accuracy: 0.7033\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 16s 2s/step - loss: 0.6273 - accuracy: 0.7217 - val_loss: 0.6435 - val_accuracy: 0.6923\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 18s 3s/step - loss: 0.6222 - accuracy: 0.7547 - val_loss: 0.6126 - val_accuracy: 0.7582\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 15s 2s/step - loss: 0.6219 - accuracy: 0.7877 - val_loss: 0.6141 - val_accuracy: 0.7582\n"
=======
      "Epoch 1/20\n",
      "7/7 [==============================] - 64s 9s/step - loss: 1.9965 - accuracy: 0.5467 - val_loss: 0.7360 - val_accuracy: 0.1522\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 66s 10s/step - loss: 0.7143 - accuracy: 0.1729 - val_loss: 0.6926 - val_accuracy: 0.7935\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 63s 9s/step - loss: 0.7165 - accuracy: 0.6963 - val_loss: 0.6970 - val_accuracy: 0.1522\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 57s 8s/step - loss: 0.7124 - accuracy: 0.1916 - val_loss: 0.6977 - val_accuracy: 0.1522\n",
      "Epoch 5/20\n",
      "2/7 [=======>......................] - ETA: 39s - loss: 0.6839 - accuracy: 0.1562"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "# Set the epocks\n",
    "# ทำ stop + validation\n",
    "epochs = 10\n",
    "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights)\n",
    "\n",
    "#history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_32 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_17 (Rescaling)    (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " tf.cast_10 (TFOpLambda)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " xception (Functional)       (None, 8, 8, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_13  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 2049      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 65s 9s/step - loss: 0.5904 - binary_accuracy: 0.7736 - val_loss: 0.6072 - val_binary_accuracy: 0.6703\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 65s 10s/step - loss: 0.5509 - binary_accuracy: 0.7500 - val_loss: 0.6066 - val_binary_accuracy: 0.6703\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 65s 9s/step - loss: 0.4722 - binary_accuracy: 0.8302 - val_loss: 0.5548 - val_binary_accuracy: 0.7253\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 72s 10s/step - loss: 0.4298 - binary_accuracy: 0.8868 - val_loss: 0.5419 - val_binary_accuracy: 0.7253\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 59s 8s/step - loss: 0.3587 - binary_accuracy: 0.9057 - val_loss: 0.5289 - val_binary_accuracy: 0.7253\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 61s 9s/step - loss: 0.2858 - binary_accuracy: 0.9340 - val_loss: 0.4876 - val_binary_accuracy: 0.7802\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 71s 11s/step - loss: 0.2440 - binary_accuracy: 0.9575 - val_loss: 0.4964 - val_binary_accuracy: 0.7473\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 88s 13s/step - loss: 0.1721 - binary_accuracy: 0.9623 - val_loss: 0.5057 - val_binary_accuracy: 0.7582\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 70s 10s/step - loss: 0.1417 - binary_accuracy: 0.9764 - val_loss: 0.4937 - val_binary_accuracy: 0.7582\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 75s 10s/step - loss: 0.1154 - binary_accuracy: 0.9717 - val_loss: 0.4766 - val_binary_accuracy: 0.8022\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 73s 10s/step - loss: 0.0672 - binary_accuracy: 1.0000 - val_loss: 0.5567 - val_binary_accuracy: 0.8132\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 73s 10s/step - loss: 0.0449 - binary_accuracy: 1.0000 - val_loss: 0.5329 - val_binary_accuracy: 0.7582\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 74s 11s/step - loss: 0.0414 - binary_accuracy: 0.9953 - val_loss: 0.6037 - val_binary_accuracy: 0.8132\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 74s 11s/step - loss: 0.0291 - binary_accuracy: 1.0000 - val_loss: 0.5582 - val_binary_accuracy: 0.8242\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 72s 10s/step - loss: 0.0176 - binary_accuracy: 1.0000 - val_loss: 0.5975 - val_binary_accuracy: 0.8022\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 15\n",
    "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_transform(pred):\n",
    "    if pred > 0.5:\n",
    "        predicted = 1\n",
    "    else:\n",
    "        predicted = 0\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 61,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "\n",
    "vfunc = np.vectorize(binary_transform)\n",
    "y_pred = vfunc(pred)\n",
    "actual = x_test"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=class_names)\n",
    "disp.plot()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "23bf0724a01b6ea9814e66f76182ea78c0ee849a72ca257c0e116bf83bb4960a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
