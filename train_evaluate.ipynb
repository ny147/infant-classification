{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ny147/infant-classification/blob/release/train_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cpHscK9W4KEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c69f5cc-8ebb-4f62-b758-8c8402575816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting focal_loss\n",
            "  Downloading focal_loss-0.0.7-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal_loss) (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.47.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.14.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.26.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (4.1.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.21.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.6.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (14.0.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal_loss) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2->focal_loss) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.2.0)\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.7\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa, librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import shutil\n",
        "!pip install focal_loss\n",
        "from focal_loss import BinaryFocalLoss\n",
        "#import ftransc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Colab"
      ],
      "metadata": {
        "id": "kvNMNbwc5MmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/Infant_cry\"\n",
        "# train_directory = path + '/mel_spectrogram/train_oneclass/hungry_one'\n",
        "# test_directory = path + '/mel_spectrogram/test_oneclass/hungry_one'\n",
        "# Matlab data\n",
        "train_directory = path + '/mfcc_matlab/train/'\n",
        "test_directory = path + '/mfcc_matlab/test/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1P1SA9q4LFI",
        "outputId": "dcee46d5-3d71-469c-ab7f-ed6c6f04e845"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local "
      ],
      "metadata": {
        "id": "k1BjHEUS5uZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_directory = path + '/data_matlab/train/'\n",
        "# test_directory = path + '/data_matlab/test/'"
      ],
      "metadata": {
        "id": "R3-uUE3m5rWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FDsbZ0NX4KEg",
        "outputId": "d9d569bf-0ba9-454c-f4f1-01a4387ffbe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 306 files belonging to 2 classes.\n",
            "Found 151 files belonging to 2 classes.\n",
            "['hungry', 'non_hungry']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_directory, labels='inferred', label_mode='int', image_size=(256, 256), seed=321,\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_directory, labels='inferred', label_mode='int', image_size=(256, 256),\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMp3ZErr4KEi"
      },
      "outputs": [],
      "source": [
        "## create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WRnYz0BQ4KEi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SGjcs6ok4KEj"
      },
      "outputs": [],
      "source": [
        "x_train=[]\n",
        "y_train=[]\n",
        "for images, labels in train_ds.unbatch().take(-1):\n",
        "    x_train.append(images.numpy())\n",
        "    y_train.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "52Syhv1s4KEj"
      },
      "outputs": [],
      "source": [
        "x_test=[]\n",
        "y_test=[]\n",
        "for images, labels in test_ds.unbatch().take(-1):\n",
        "    x_test.append(images.numpy())\n",
        "    y_test.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pTeqzMX54KEk"
      },
      "outputs": [],
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KuLx5bbv4KEk"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "def create_weight(n_sample,n_class,n_class_sample):\n",
        "    weight = n_sample/(n_class*n_class_sample)\n",
        "    return weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_PLcfLrI4KEl"
      },
      "outputs": [],
      "source": [
        "class_weights = {0:0, 1:0}\n",
        "class_count = np.array([255,51])\n",
        "for i in range(num_classes):\n",
        "    class_weights[i]=create_weight(306,num_classes,class_count[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CXXvqKtk4KEl",
        "outputId": "29cfd579-d1c4-4dc0-ea14-3ee1b5503a4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_4 (Rescaling)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " tf.cast_2 (TFOpLambda)      (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " xception (Functional)       (None, 8, 8, 2048)        20861480  \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,863,529\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.applications.Xception(\n",
        "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(img_height, img_width, 3),\n",
        "    include_top=False,\n",
        ")  # Do not include the ImageNet classifier at the top.\n",
        "\n",
        "# base_model = tf.keras.applications.ResNet50V2(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_tensor=None,\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     pooling=None,\n",
        "#     # classes=1000,\n",
        "#     classifier_activation=\"softmax\",\n",
        "# )\n",
        "# base_model = tf.keras.applications.InceptionResNetV2(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     pooling=None,\n",
        "#     classifier_activation=\"softmax\"\n",
        "# )\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create new model on top\n",
        "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "#x = data_augmentation(inputs)  # Apply random data augmentation\n",
        "\n",
        "# Pre-trained Xception weights requires that input be scaled\n",
        "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
        "# outputs: `(inputs * scale) + offset`\n",
        "scale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
        "x = scale_layer(inputs)\n",
        "\n",
        "x = tf.cast(x,tf.float32)\n",
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "# x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(1)(x)\n",
        "outputs = tf.keras.layers.Activation('sigmoid')(outputs)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5mS95CLp4KEm",
        "outputId": "5136ae7b-9af4-4f7a-e9df-4c75a736582e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_5 (Rescaling)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 256, 256, 256)     7168      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 128, 128, 256)    0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 128, 128, 128)     295040    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 64, 64, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 64, 64, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 65536)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                4194368   \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,570,433\n",
            "Trainable params: 4,570,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "            tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2,2)),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ENIr5nXA4KEn"
      },
      "outputs": [],
      "source": [
        "#resnet \n",
        "#inception v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "B-6CMHob4KEo"
      },
      "outputs": [],
      "source": [
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 25)\n",
        "earlystop_callback2 = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy',patience = 25)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "# loss_fn = BinaryFocalLoss(gamma=2)\n",
        "optimizer = tf.keras.optimizers.Adam()# modify weight in Adam\n",
        "metrics = ['accuracy']\n",
        "model.compile (optimizer = optimizer,loss =  loss_fn,metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2I_oiDJ94KEo",
        "outputId": "4acf0310-f81f-48ed-8400-d418597da1c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 4s 398ms/step - loss: 1.8394 - accuracy: 0.5280 - val_loss: 0.5868 - val_accuracy: 0.8478\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.7246 - accuracy: 0.4299 - val_loss: 0.6972 - val_accuracy: 0.6848\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.7163 - accuracy: 0.7290 - val_loss: 0.6540 - val_accuracy: 0.7283\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.6989 - accuracy: 0.5000 - val_loss: 0.6965 - val_accuracy: 0.3804\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.6931 - accuracy: 0.4019 - val_loss: 0.6887 - val_accuracy: 0.6848\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.6852 - accuracy: 0.5935 - val_loss: 0.6767 - val_accuracy: 0.6739\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.6809 - accuracy: 0.6495 - val_loss: 0.6851 - val_accuracy: 0.6848\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.6545 - accuracy: 0.6916 - val_loss: 0.6399 - val_accuracy: 0.6848\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.6390 - accuracy: 0.6355 - val_loss: 0.5806 - val_accuracy: 0.6848\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.5955 - accuracy: 0.7009 - val_loss: 0.8382 - val_accuracy: 0.1848\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.5670 - accuracy: 0.5841 - val_loss: 0.5400 - val_accuracy: 0.6739\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.4840 - accuracy: 0.7383 - val_loss: 0.5856 - val_accuracy: 0.6739\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.5697 - accuracy: 0.7009 - val_loss: 0.6003 - val_accuracy: 0.6413\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.4755 - accuracy: 0.7570 - val_loss: 0.6193 - val_accuracy: 0.7174\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.4068 - accuracy: 0.7383 - val_loss: 0.6298 - val_accuracy: 0.6304\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.3168 - accuracy: 0.8692 - val_loss: 0.7695 - val_accuracy: 0.7717\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.2703 - accuracy: 0.8692 - val_loss: 0.8883 - val_accuracy: 0.7174\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.2187 - accuracy: 0.8738 - val_loss: 1.0675 - val_accuracy: 0.5978\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.1876 - accuracy: 0.8925 - val_loss: 1.2848 - val_accuracy: 0.7717\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.1348 - accuracy: 0.9252 - val_loss: 1.2498 - val_accuracy: 0.6957\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 3s 368ms/step - loss: 0.1152 - accuracy: 0.9112 - val_loss: 1.6365 - val_accuracy: 0.7391\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0731 - accuracy: 0.9486 - val_loss: 1.5716 - val_accuracy: 0.7283\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 0.0476 - accuracy: 0.9813 - val_loss: 1.9407 - val_accuracy: 0.7609\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 3s 371ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.8360 - val_accuracy: 0.7065\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.8818 - val_accuracy: 0.7826\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 3s 368ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.3718 - val_accuracy: 0.6957\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0248 - accuracy: 0.9953 - val_loss: 2.2238 - val_accuracy: 0.8152\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 3s 368ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.2050 - val_accuracy: 0.8043\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.2134 - val_accuracy: 0.7717\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.3912 - val_accuracy: 0.7826\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 9.0131e-04 - accuracy: 1.0000 - val_loss: 2.5738 - val_accuracy: 0.7826\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 3s 373ms/step - loss: 4.2247e-04 - accuracy: 1.0000 - val_loss: 2.7018 - val_accuracy: 0.7826\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 3.4609e-04 - accuracy: 1.0000 - val_loss: 2.7729 - val_accuracy: 0.7826\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 3s 368ms/step - loss: 3.2295e-04 - accuracy: 1.0000 - val_loss: 2.8109 - val_accuracy: 0.7826\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 2.2296e-04 - accuracy: 1.0000 - val_loss: 2.8314 - val_accuracy: 0.7826\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 3s 375ms/step - loss: 2.1981e-04 - accuracy: 1.0000 - val_loss: 2.8436 - val_accuracy: 0.7826\n"
          ]
        }
      ],
      "source": [
        "# Set the epocks\n",
        "# ทำ stop + validation\n",
        "epochs = 50\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights,callbacks = [earlystop_callback,earlystop_callback2])\n",
        "# history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights)\n",
        "#history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "G9oorLuK4KEo",
        "outputId": "22c02999-cc5d-4fc4-ea28-6706b20de5e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_5 (Rescaling)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 256, 256, 256)     7168      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 128, 128, 256)    0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 128, 128, 128)     295040    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 64, 64, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 64, 64, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 65536)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                4194368   \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,570,433\n",
            "Trainable params: 4,570,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 3s 402ms/step - loss: 2.2355e-04 - binary_accuracy: 1.0000 - val_loss: 2.8555 - val_binary_accuracy: 0.7826\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 2.1678e-04 - binary_accuracy: 1.0000 - val_loss: 2.8636 - val_binary_accuracy: 0.7826\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 1.5423e-04 - binary_accuracy: 1.0000 - val_loss: 2.8746 - val_binary_accuracy: 0.7826\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 1.3407e-04 - binary_accuracy: 1.0000 - val_loss: 2.8737 - val_binary_accuracy: 0.7826\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 1.3613e-04 - binary_accuracy: 1.0000 - val_loss: 2.8789 - val_binary_accuracy: 0.7826\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 1.2369e-04 - binary_accuracy: 1.0000 - val_loss: 2.8838 - val_binary_accuracy: 0.7826\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 3s 370ms/step - loss: 9.6901e-05 - binary_accuracy: 1.0000 - val_loss: 2.8849 - val_binary_accuracy: 0.7826\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 1.2136e-04 - binary_accuracy: 1.0000 - val_loss: 2.8892 - val_binary_accuracy: 0.7826\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 3s 371ms/step - loss: 1.1508e-04 - binary_accuracy: 1.0000 - val_loss: 2.9014 - val_binary_accuracy: 0.7826\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 3s 369ms/step - loss: 9.6877e-05 - binary_accuracy: 1.0000 - val_loss: 2.9177 - val_binary_accuracy: 0.7826\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 3s 368ms/step - loss: 9.1745e-05 - binary_accuracy: 1.0000 - val_loss: 2.9351 - val_binary_accuracy: 0.7826\n"
          ]
        }
      ],
      "source": [
        "earlystop_callback2 = tf.keras.callbacks.EarlyStopping(monitor = 'binary_accuracy',patience = 10,min_delta=0)\n",
        "base_model.trainable = True\n",
        "model.summary()\n",
        "# loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss = loss_fn,\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,callbacks = [earlystop_callback,earlystop_callback2],class_weight = class_weights)\n",
        "# history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "cQ7QKhSO4KEp"
      },
      "outputs": [],
      "source": [
        "def binary_transform(pred):\n",
        "    if pred > 0.5:\n",
        "        predicted = 1\n",
        "    else:\n",
        "        predicted = 0\n",
        "    return predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NTHyhXUb4KEp"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(x_test)\n",
        "\n",
        "vfunc = np.vectorize(binary_transform)\n",
        "y_pred = vfunc(pred)\n",
        "actual = x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "a3MuHsl24KEp",
        "outputId": "6fe46f76-a066-42d6-97ea-4577041fa634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=class_names)\n",
        "disp.plot()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xsWVsk_w4KEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f51dcc7a-c87e-4b72-8602-a27638e7bcf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Hungry       0.86      0.94      0.89       127\n",
            "  Non_hungry       0.33      0.17      0.22        24\n",
            "\n",
            "    accuracy                           0.81       151\n",
            "   macro avg       0.59      0.55      0.56       151\n",
            "weighted avg       0.77      0.81      0.79       151\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred,target_names=[\"Hungry\",\"Non_hungry\"]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MICls6lpDG0E"
      },
      "execution_count": 29,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "23bf0724a01b6ea9814e66f76182ea78c0ee849a72ca257c0e116bf83bb4960a"
      }
    },
    "colab": {
      "name": "train_evaluate.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}