{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ny147/infant-classification/blob/release/train_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cpHscK9W4KEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef6c643c-1fd3-49f1-8a70-d44a10fdad64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa, librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import shutil\n",
        "# !pip install focal_loss\n",
        "# from focal_loss import BinaryFocalLoss\n",
        "#import ftransc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Colab"
      ],
      "metadata": {
        "id": "kvNMNbwc5MmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/Infant_cry\"\n",
        "train_directory = path + '/mel_spectrogram/train_oneclass/hungry_one'\n",
        "test_directory = path + '/mel_spectrogram/test_oneclass/hungry_one'\n",
        "# Matlab data\n",
        "# train_directory = path + '/mfcc_matlab/train/'\n",
        "# test_directory = path + '/mfcc_matlab/test/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1P1SA9q4LFI",
        "outputId": "b9b92f94-7949-48e1-e80b-34da90ff22dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local "
      ],
      "metadata": {
        "id": "k1BjHEUS5uZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_directory = path + '/data_matlab/train/'\n",
        "# test_directory = path + '/data_matlab/test/'"
      ],
      "metadata": {
        "id": "R3-uUE3m5rWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FDsbZ0NX4KEg",
        "outputId": "f3fe7a8b-1344-47a9-809c-c24c66d6017b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 303 files belonging to 2 classes.\n",
            "Found 154 files belonging to 2 classes.\n",
            "['hungry', 'non_hungry']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_directory, labels='inferred', label_mode='int', image_size=(256, 256), seed=321,\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_directory, labels='inferred', label_mode='int', image_size=(256, 256),\n",
        "    validation_split=None, subset=None)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMp3ZErr4KEi"
      },
      "outputs": [],
      "source": [
        "## create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WRnYz0BQ4KEi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SGjcs6ok4KEj"
      },
      "outputs": [],
      "source": [
        "x_train=[]\n",
        "y_train=[]\n",
        "for images, labels in train_ds.unbatch().take(-1):\n",
        "    x_train.append(images.numpy())\n",
        "    y_train.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "52Syhv1s4KEj"
      },
      "outputs": [],
      "source": [
        "x_test=[]\n",
        "y_test=[]\n",
        "for images, labels in test_ds.unbatch().take(-1):\n",
        "    x_test.append(images.numpy())\n",
        "    y_test.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pTeqzMX54KEk"
      },
      "outputs": [],
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KuLx5bbv4KEk"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "def create_weight(n_sample,n_class,n_class_sample):\n",
        "    weight = n_sample/(n_class*n_class_sample)\n",
        "    return weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_PLcfLrI4KEl"
      },
      "outputs": [],
      "source": [
        "class_weights = {0:0, 1:0}\n",
        "class_count = np.array([254,49])\n",
        "for i in range(num_classes):\n",
        "    class_weights[i]=create_weight(306,num_classes,class_count[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CXXvqKtk4KEl",
        "outputId": "4587f39e-b398-41e8-c733-763abd1f49b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "80150528/80134624 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " tf.cast (TFOpLambda)        (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " vgg19 (Functional)          (None, 8, 8, 512)         20024384  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 513       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,024,897\n",
            "Trainable params: 513\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# base_model = tf.keras.applications.Xception(\n",
        "#     weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     include_top=False,\n",
        "# )  # Do not include the ImageNet classifier at the top.\n",
        "\n",
        "# base_model = tf.keras.applications.ResNet50V2(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_tensor=None,\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     pooling=None,\n",
        "#     # classes=1000,\n",
        "#     classifier_activation=\"softmax\",\n",
        "# )\n",
        "# base_model = tf.keras.applications.InceptionResNetV2(\n",
        "#     include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_shape=(img_height, img_width, 3),\n",
        "#     pooling=None,\n",
        "#     classifier_activation=\"softmax\"\n",
        "# )\n",
        "\n",
        "base_model = tf.keras.applications.VGG19(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(img_height, img_width, 3),\n",
        "    pooling=None,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create new model on top\n",
        "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "#x = data_augmentation(inputs)  # Apply random data augmentation\n",
        "\n",
        "# Pre-trained Xception weights requires that input be scaled\n",
        "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
        "# outputs: `(inputs * scale) + offset`\n",
        "scale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
        "x = scale_layer(inputs)\n",
        "\n",
        "x = tf.cast(x,tf.float32)\n",
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "# x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(1)(x)\n",
        "outputs = tf.keras.layers.Activation('sigmoid')(outputs)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5mS95CLp4KEm"
      },
      "outputs": [],
      "source": [
        "# model = tf.keras.Sequential([\n",
        "#             tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "#             tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "#             tf.keras.layers.MaxPooling2D((2,2)),\n",
        "#             tf.keras.layers.Dropout(0.2),\n",
        "#             tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),            \n",
        "#             tf.keras.layers.MaxPooling2D((2,2)),\n",
        "#             tf.keras.layers.Dropout(0.2),\n",
        "#             tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "#             tf.keras.layers.MaxPooling2D((2,2)),\n",
        "#             tf.keras.layers.Flatten(),\n",
        "#             tf.keras.layers.Dense(64, activation='relu'),\n",
        "#             tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "#         ])\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ENIr5nXA4KEn"
      },
      "outputs": [],
      "source": [
        "#resnet \n",
        "#inception v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "B-6CMHob4KEo"
      },
      "outputs": [],
      "source": [
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 10)\n",
        "earlystop_callback2 = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy',patience = 10)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "# loss_fn = BinaryFocalLoss(gamma=2)\n",
        "optimizer = tf.keras.optimizers.Adam()# modify weight in Adam\n",
        "metrics = ['accuracy']\n",
        "model.compile (optimizer = optimizer,loss =  loss_fn,metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2I_oiDJ94KEo",
        "outputId": "72b7971d-d52e-4483-ab61-93aa5b9f4c10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 20s 912ms/step - loss: 1.0148 - accuracy: 0.7736 - val_loss: 0.6518 - val_accuracy: 0.8352\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.7064 - accuracy: 0.8396 - val_loss: 0.6923 - val_accuracy: 0.8352\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.6975 - accuracy: 0.6368 - val_loss: 0.6928 - val_accuracy: 0.7473\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 2s 363ms/step - loss: 0.6978 - accuracy: 0.2217 - val_loss: 0.6971 - val_accuracy: 0.2088\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.6965 - accuracy: 0.2972 - val_loss: 0.6981 - val_accuracy: 0.2527\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.6949 - accuracy: 0.3868 - val_loss: 0.6981 - val_accuracy: 0.4066\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.6887 - accuracy: 0.4717 - val_loss: 0.6978 - val_accuracy: 0.4286\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 2s 363ms/step - loss: 0.6921 - accuracy: 0.7547 - val_loss: 0.7177 - val_accuracy: 0.3187\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 2s 362ms/step - loss: 0.6814 - accuracy: 0.4245 - val_loss: 0.6848 - val_accuracy: 0.4505\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 3s 363ms/step - loss: 0.6380 - accuracy: 0.5330 - val_loss: 0.6166 - val_accuracy: 0.6154\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 3s 392ms/step - loss: 0.6246 - accuracy: 0.4906 - val_loss: 0.6393 - val_accuracy: 0.6154\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 3s 393ms/step - loss: 0.5667 - accuracy: 0.6887 - val_loss: 0.6636 - val_accuracy: 0.6264\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.4943 - accuracy: 0.7453 - val_loss: 0.8194 - val_accuracy: 0.5275\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 2s 363ms/step - loss: 0.4913 - accuracy: 0.6368 - val_loss: 0.6012 - val_accuracy: 0.6593\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.3816 - accuracy: 0.7972 - val_loss: 0.5613 - val_accuracy: 0.7143\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.3832 - accuracy: 0.8396 - val_loss: 0.7449 - val_accuracy: 0.6264\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.3220 - accuracy: 0.7736 - val_loss: 0.4669 - val_accuracy: 0.7802\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.3142 - accuracy: 0.8208 - val_loss: 0.5687 - val_accuracy: 0.7582\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.2784 - accuracy: 0.8632 - val_loss: 0.6734 - val_accuracy: 0.7033\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.2903 - accuracy: 0.8302 - val_loss: 0.5048 - val_accuracy: 0.7912\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.3531 - accuracy: 0.8302 - val_loss: 0.5773 - val_accuracy: 0.7582\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.2297 - accuracy: 0.9104 - val_loss: 0.5255 - val_accuracy: 0.8132\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.2541 - accuracy: 0.9057 - val_loss: 0.5365 - val_accuracy: 0.7802\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.2422 - accuracy: 0.8821 - val_loss: 0.5652 - val_accuracy: 0.7582\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.1993 - accuracy: 0.8962 - val_loss: 0.6113 - val_accuracy: 0.7692\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.1521 - accuracy: 0.9481 - val_loss: 0.7889 - val_accuracy: 0.6923\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 3s 372ms/step - loss: 0.1601 - accuracy: 0.9151 - val_loss: 0.6077 - val_accuracy: 0.7912\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 3s 371ms/step - loss: 0.1034 - accuracy: 0.9717 - val_loss: 0.8027 - val_accuracy: 0.7473\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.0834 - accuracy: 0.9481 - val_loss: 0.7831 - val_accuracy: 0.8571\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0894 - accuracy: 0.9764 - val_loss: 0.8524 - val_accuracy: 0.7912\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 3s 363ms/step - loss: 0.0654 - accuracy: 0.9858 - val_loss: 0.7067 - val_accuracy: 0.8022\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 3s 364ms/step - loss: 0.0773 - accuracy: 0.9575 - val_loss: 0.5945 - val_accuracy: 0.8132\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.0680 - accuracy: 0.9858 - val_loss: 0.6020 - val_accuracy: 0.8242\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.0521 - accuracy: 0.9764 - val_loss: 1.0300 - val_accuracy: 0.8022\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0382 - accuracy: 0.9858 - val_loss: 0.9265 - val_accuracy: 0.8462\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.0884 - accuracy: 0.9717 - val_loss: 0.9252 - val_accuracy: 0.8022\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.0484 - accuracy: 0.9764 - val_loss: 0.8579 - val_accuracy: 0.8791\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.8571\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.8344 - val_accuracy: 0.8571\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.9323 - val_accuracy: 0.8571\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0100 - accuracy: 0.9953 - val_loss: 0.9609 - val_accuracy: 0.8681\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0386 - val_accuracy: 0.8681\n"
          ]
        }
      ],
      "source": [
        "# Set the epocks\n",
        "# ทำ stop + validation\n",
        "epochs = 50\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights,callbacks = [earlystop_callback,earlystop_callback2])\n",
        "# history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights)\n",
        "#history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "G9oorLuK4KEo",
        "outputId": "aca37ad0-ab6b-4076-d2b4-d1d37277f78a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_1 (Rescaling)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 256, 256, 256)     7168      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 128, 128, 256)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 128)     295040    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 64, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4194368   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,570,433\n",
            "Trainable params: 4,570,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 4s 400ms/step - loss: 0.0046 - binary_accuracy: 1.0000 - val_loss: 1.0524 - val_binary_accuracy: 0.8571\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0113 - binary_accuracy: 1.0000 - val_loss: 1.0556 - val_binary_accuracy: 0.8571\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 1.0564 - val_binary_accuracy: 0.8571\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.0054 - binary_accuracy: 1.0000 - val_loss: 1.0571 - val_binary_accuracy: 0.8571\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 1.0581 - val_binary_accuracy: 0.8681\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 3s 365ms/step - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 1.0583 - val_binary_accuracy: 0.8681\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.0064 - binary_accuracy: 1.0000 - val_loss: 1.0585 - val_binary_accuracy: 0.8681\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0052 - binary_accuracy: 1.0000 - val_loss: 1.0579 - val_binary_accuracy: 0.8681\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 3s 368ms/step - loss: 0.0070 - binary_accuracy: 1.0000 - val_loss: 1.0630 - val_binary_accuracy: 0.8681\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 3s 366ms/step - loss: 0.0051 - binary_accuracy: 1.0000 - val_loss: 1.0670 - val_binary_accuracy: 0.8681\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 3s 367ms/step - loss: 0.0074 - binary_accuracy: 1.0000 - val_loss: 1.0660 - val_binary_accuracy: 0.8791\n"
          ]
        }
      ],
      "source": [
        "earlystop_callback2 = tf.keras.callbacks.EarlyStopping(monitor = 'binary_accuracy',patience = 4,min_delta=0)\n",
        "base_model.trainable = True\n",
        "model.summary()\n",
        "# loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss = loss_fn,\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 50\n",
        "history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,callbacks = [earlystop_callback,earlystop_callback2],class_weight = class_weights)\n",
        "# history = model.fit(x_train, y_train, epochs=epochs,validation_split=0.3,class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cQ7QKhSO4KEp"
      },
      "outputs": [],
      "source": [
        "def binary_transform(pred):\n",
        "    if pred > 0.5:\n",
        "        predicted = 1\n",
        "    else:\n",
        "        predicted = 0\n",
        "    return predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NTHyhXUb4KEp"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(x_test)\n",
        "\n",
        "vfunc = np.vectorize(binary_transform)\n",
        "y_pred = vfunc(pred)\n",
        "actual = x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "a3MuHsl24KEp",
        "outputId": "ef6fcda3-53c0-4ce7-f72d-6b69db0f5c28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=class_names)\n",
        "disp.plot()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xsWVsk_w4KEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "044c6c6e-b419-4dc0-d399-1b10d6b19003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Hungry       0.85      0.91      0.88       128\n",
            "  Non_hungry       0.35      0.23      0.28        26\n",
            "\n",
            "    accuracy                           0.80       154\n",
            "   macro avg       0.60      0.57      0.58       154\n",
            "weighted avg       0.77      0.80      0.78       154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred,target_names=[\"Hungry\",\"Non_hungry\"]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MICls6lpDG0E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "23bf0724a01b6ea9814e66f76182ea78c0ee849a72ca257c0e116bf83bb4960a"
      }
    },
    "colab": {
      "name": "train_evaluate.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}